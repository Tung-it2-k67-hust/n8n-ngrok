# Phân tích chi tiết: 3.3_HDFS_vn.pdf

Dưới đây là tài liệu được tái cấu trúc và phân tích chuyên sâu về **Hadoop HDFS (Hadoop Distributed File System)** dựa trên nội dung slide bạn cung cấp, được trình bày dưới dạng Markdown chuyên nghiệp.

---

# Chương 3: Hệ thống Tập tin Phân tán - Hadoop HDFS

## 1. Tổng quan về HDFS (Overview)

**HDFS (Hadoop Distributed File System)** là một thành phần cốt lõi của hệ sinh thái Hadoop, thiết kế để lưu trữ dữ liệu lớn với chi phí thấp và độ tin cậy cao.

### 1.1. Đặc điểm thiết kế
HDFS khác biệt so với các hệ thống tập tin truyền thống (như NTFS, ext4) ở các điểm sau:

| Đặc điểm | Mô tả |
| :--- | :--- |
| **Optimized for Big Data** | Tối ưu hóa để lưu trữ các tệp có kích thước lớn (từ vài trăm MB đến vài TB). |
| **Hierarchy File System** | Cung cấp cấu trúc cây thư mục phân cấp (hierarchical), tương tự UNIX (ví dụ: `/hust/soict/hello.txt`). |
| **Permission Control** | Hỗ trợ cơ chế phân quyền và kiểm soát người dùng (Read, Write, Execute) tương tự UNIX. |
| **Write Once, Read Many (WORM)** | Mô hình truy cập: <br>• Chỉ hỗ trợ ghi thêm dữ liệu vào cuối tệp (**APPEND**).<br>• Không cho phép ghi đè lên phần dữ liệu đã tồn tại.<br>• Lý tưởng cho việc lưu trữ log, dữ liệu cảm biến, hoặc xử lý batch. |

### 1.2. Ví dụ minh họa mô hình WORM
Trong các hệ thống file truyền thống, bạn có thể sửa một câu trong file Word. Trong HDFS, bạn chỉ có thể nối (append) thêm câu mới vào cuối file.

---

## 2. Nguyên lý thiết kế cốt lõi (Core Design Principles)

HDFS được xây dựng dựa trên 3 nguyên tắc chính để đảm bảo khả năng mở rộng và chịu lỗi.

### 2.1. I/O Pattern (Mẫu Nhập/Xuất)
*   **Chỉ ghi thêm (Append-only):** Giảm thiểu sự phức tạp trong cơ chế điều khiển tương tranh (concurrency control). Không cần khóa các block dữ liệu nhỏ khi ghi.
*   **Đọc nhiều hơn Ghi:** Phù hợp với các bài toán phân tích dữ liệu (Data Analytics), nơi dữ liệu được ghi một lần và được đọc đi đọc lại nhiều lần.

### 2.2. Phân tán dữ liệu (Data Striping)
HDFS không lưu trữ tệp như một khối liền mạch.
*   **Cách hoạt động:** Tệp lớn được chia thành các khối dữ liệu (**Chunks/Blocks**) có kích thước cố định (thường là **128MB** hoặc **256MB**, mặc dù slide đề cập 64MB).
*   **Lợi ích:**
    *   **Giảm kích thước Metadata:** Name node chỉ cần quản lý vị trí của các block thay vì phải quản lý vị trí của từng byte trong tệp.
    *   **Giảm chi phí truyền dữ liệu:** Cho phép đọc/ghi song song trên nhiều node.

### 2.3. Nhân bản dữ liệu (Replication)
Để đảm bảo độ tin cậy (Fault Tolerance), HDFS sao chép dữ liệu trên nhiều node.
*   **Quy tắc:** Mỗi block thông thường được sao làm **3 nhân bản (replication factor = 3)**.
*   **Lưu trữ:** Các nhân bản được đặt trên các Data Node khác nhau (có thể khác rack để chống lỗi phần cứng toàn diện).

### 2.4. Cơ chế chịu lỗi (Fault Tolerance)
*   **Data Node:** Nếu một Data Node bị lỗi, Name Node sẽ phát hiện ra (thông qua heartbeat) và khởi động quá trình **tái nhân bản (Re-replication)** để tạo lại các block bị mất trên các node còn sống.
*   **Name Node:**
    *   **Vấn đề:** Name Node là điểm đơn (Single Point of Failure). Nếu nó hỏng, hệ thống không thể truy cập dữ liệu.
    *   **Giải pháp (theo slide):** Sử dụng **Secondary Name Node (SNN)**.
        *   SNN định kỳ sao chép checkpoint của metadata từ Primary NN.
        *   Khi khởi động, SNN có thể hỏi các Data Node để tái tạo lại trạng thái, tránh cơ chế đồng bộ phức tạp (tuy nhiên, trong các phiên bản Hadoop mới, SNN đã được thay thế bởi HA Active/Standby Name Node).

---

## 3. Kiến trúc Master/Slave

HDFS vận hành theo mô hình kiến trúc phân cấp Client-Server.

### 3.1. Components

| Thành phần | Vai trò | Chức năng chính |
| :--- | :--- | :--- |
| **Name Node (Master)** | Quản lý Metadata | • Quản lý không gian tên (namespace) của hệ thống tệp.<br>• Lưu trữ ánh xạ (mapping) giữa tệp và các Block ID.<br>• Giám sát trạng thái của Data Node (thông qua Heartbeat). |
| **Data Node (Slave)** | Lưu trữ dữ liệu thực | • Thực hiện các thao tác I/O ghi/đọc trực tiếp lên đĩa cứng.<br>• Báo cáo trạng thái block cho Name Node.<br>• Tạo Block theo yêu cầu của Client. |
| **Client** | Truy cập dữ liệu | • Kết nối với Name Node để lấy thông tin location của Block.<br>• Trực tiếp đọc/ghi dữ liệu từ Data Node. |

### 3.2. Quy trình ghi dữ liệu (Write Flow)
1.  Client yêu cầu Name Node tạo tệp mới.
2.  Name Node xác định vị trí các Data Node sẽ lưu các Block.
3.  Client ghi dữ liệu trực tiếp vào Data Node (dạng pipeline).

---

## 4. Code Samples & Implementation

Mặc dù HDFS là một hệ thống file, chúng ta thường tương tác với nó thông qua các thư viện lập trình hoặc Command Line.

### 4.1. Command Line Interface (CLI)
Đây là cách phổ biến nhất để quản lý HDFS.

```bash
# 1. Liệt kê các file trong thư mục gốc của HDFS
hdfs dfs -ls /

# 2. Đẩy file từ hệ thống local lên HDFS
# Cú pháp: hdfs dfs -put <local_path> <hdfs_path>
hdfs dfs -put /home/user/data.log /user/hadoop/input/data.log

# 3. Đọc nội dung file từ HDFS
hdfs dfs -cat /user/hadoop/input/data.log

# 4. Tạo thư mục
hdfs dfs -mkdir /project/data

# 5. Xem thông tin về cluster và dung lượng đĩa
hdfs dfsadmin -report
```

### 4.2. Java API (Sample Code)
Đây là ví dụ về cách đọc một file từ HDFS bằng Java API (thường dùng trong các ứng dụng MapReduce hoặc Spark).

```java
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.fs.FSDataInputStream;
import java.io.BufferedReader;
import java.io.InputStreamReader;
import java.io.IOException;

public class HDFSReadExample {
    public static void main(String[] args) {
        // 1. Cấu hình Hadoop
        Configuration conf = new Configuration();
        conf.set("fs.defaultFS", "hdfs://localhost:9000");

        try {
            // 2. Lấy instance của FileSystem
            FileSystem fs = FileSystem.get(conf);
            
            // 3. Định nghĩa đường dẫn file trên HDFS
            Path file_path = new Path("/user/hadoop/input/data.txt");
            
            // 4. Mở stream để đọc dữ liệu
            if (fs.exists(file_path)) {
                FSDataInputStream in = fs.open(file_path);
                BufferedReader reader = new BufferedReader(new InputStreamReader(in));
                
                String line;
                System.out.println("--- Bắt đầu đọc file từ HDFS ---");
                while ((line = reader.readLine()) != null) {
                    System.out.println(line);
                }
                
                reader.close();
                fs.close();
            } else {
                System.out.println("File không tồn tại!");
            }
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}
```

---

## 5. Phân tích Sử dụng & Thực tiễn

### 5.1. Khi nào sử dụng HDFS? (Use Cases)
HDFS là nền tảng lưu trữ cho các hệ thống Big Data. Nó phù hợp khi:
*   Dữ liệu có dung lượng **từ Terabyte đến Petabyte**.
*   Dữ liệu có cấu trúc **bán cấu trúc (JSON, XML)** hoặc **phi cấu trúc (Log, Image, Video)**.
*   Bài toán yêu cầu **thông lượng (throughput)** đọc/ghi cao, không yêu cầu độ trễ thấp (Latency) như hệ thống giao dịch thời gian thực (OLTP).
*   Chi phí phần cứng cần được tối ưu (dùng máy chủ commodity thay vì máy chủ Mainframe đắt tiền).

### 5.2. Sử dụng như thế nào? (How to use)
1.  **Cài đặt Cluster:** Cài đặt Hadoop (HDFS + YARN) trên nhiều máy chủ (nodes).
2.  **Định dạng HDFS:** Chạy lệnh `hdfs namenode -format`.
3.  **Start Services:** Khởi động Name Node và Data Node.
4.  **Truy cập:**
    *   Dùng CLI (`hdfs dfs`).
    *   Dùng API (Java, Python via `hadoop-fs`).
    *   Dùng các công cụ cao cấp hơn như **Apache Hive** (SQL trên HDFS) hoặc **Apache Spark**.

### 5.3. Ưu & Nhược điểm

| Ưu điểm (Pros) | Nhược điểm (Cons) |
| :--- | :--- |
| **Mở rộng quy mô (Scalability):** Dễ dàng thêm Node vào cluster mà không cần downtime. | **Latency cao:** Không phù hợp cho các tác vụ yêu cầu truy cập ngẫu nhiên (Random Access) nhanh. |
| **Chịu lỗi (Fault Tolerance):** Tự động phục hồi khi máy chủ hỏng. | **Name Node là điểm đơn (SPOF):** Trong các phiên bản cũ, nếu Name Node chết, toàn bộ hệ thống ngừng hoạt động. |
| **Chi phí thấp:** Hoạt động trên phần cứng thông thường (Commodity Hardware). | **Small File Problem:** Name Node tốn bộ nhớ để lưu metadata cho hàng triệu file nhỏ (dưới 1MB). |

### 5.4. Ví dụ Thực tế trong Ngành
*   **Facebook:** Lưu trữ hàng Petabyte dữ liệu log người dùng, dữ liệu ảnh, video. Sử dụng HDFS làm kho dữ liệu thô (Data Lake).
*   **LinkedIn:** Phân tích mạng lưới kết nối người dùng và lưu trữ dữ liệu hồ sơ.
*   **Các công ty E-commerce (Shopee, Tiki):** Lưu trữ log server, hành vi click chuột của người dùng để phân tích và đề xuất sản phẩm (Recommendation Engine).

---

## 6. Tóm tắt

HDFS là giải pháp lưu trữ phân tán cốt lõi, giải quyết bài toán **"Lưu trữ dữ liệu lớn với chi phí hợp lý và độ tin cậy cao"**. Thiết kế **Write-Once-Read-Many** và **Block-based** của nó đã đặt nền móng cho sự phát triển của kỷ nguyên Big Data hiện nay.

---

Chào bạn, với vai trò là một chuyên gia về Big Data và Hệ thống Phân tán, tôi sẽ phân tích và trình bày lại nội dung từ slide "3.3_HDFS_vn.pdf" một cách chi tiết, chuyên nghiệp và dễ hiểu theo đúng yêu cầu của bạn.

***

# Phân tích và Trình bày: Kiến trúc và Hoạt động của HDFS (Hadoop Distributed File System)

Tài liệu này mô tả các thành phần cốt lõi và cơ chế hoạt động của HDFS, một hệ thống tệp tin phân tán được thiết kế để lưu trữ lượng dữ liệu lớn (Big Data) trên các cụm máy chủ thông thường.

## 1. Name Node: Trung tâm điều khiển (The Master)

Name Node là thành phần quan trọng nhất trong kiến trúc HDFS, đóng vai trò như một người quản lý toàn bộ hệ thống.

### Khái niệm & Giải thích
Name Node không lưu trữ dữ liệu thực tế (payload) mà chỉ lưu trữ **siêu dữ liệu (Metadata)**. Siêu dữ liệu này giống như "bản đồ" của toàn bộ hệ thống tệp tin, giúp hệ thống biết dữ liệu đang nằm ở đâu.

**Các vai trò chính:**
*   **Quản lý Namespace (Không gian tên):** Duy trì cấu trúc thư mục và tệp tin.
*   **Lưu trữ Metadata:** Bao gồm danh sách tệp, thuộc tính (ngày tạo, quyền truy cập...), và quan trọng nhất là ánh xạ từ **tên tệp** đến các **Data Blocks (Chunks)**.
*   **Quản lý Physical Location:** Biết chính xác Block nào đang được lưu trữ trên Data Node nào.
*   **Quản lý Transaction Log:** Ghi lại nhật ký các thao tác (tạo, xóa, sửa tệp) để phục hồi trạng thái khi có sự cố.
*   **Quản lý Replication (Nhân bản):** Điều phối việc sao chép dữ liệu để đảm bảo độ sẵn sàng cao.

### Ưu & Nhược điểm
| Tiêu chí | Chi tiết |
| :--- | :--- |
| **Ưu điểm** | - **Truy xuất nhanh:** Metadata nhỏ và được lưu trong RAM, giúp việc truy vấn cấu trúc tệp tin cực nhanh.<br>- **Đơn giản hóa:** Phân loại rõ ràng giữa quản lý (Name Node) và lưu trữ (Data Node). |
| **Nhược điểm** | - **Điểm lỗi đơn (SPOF):** Nếu Name Node chết, toàn bộ hệ thống không thể truy cập (trừ khi có Secondary Name Node hoặc HA setup).<br>- **Ngưỡng giới hạn:** Kích thước RAM ограни chế số lượng tệp/phần tử có thể lưu trữ (mặc dù dữ liệu thực tế là vô hạn). |

### Ví dụ thực tế
Trong một công ty phân tích dữ liệu lớn (ví dụ: VNG, FPT), Name Node giống như **thư ký tòa nhà**. Khi bạn yêu cầu "Tôi cần file log của server A ngày hôm qua", thư ký (Name Node) tra sổ (RAM) và chỉ bạn đến đúng "Phòng 3, Tầng 2" (Data Node 3). Thư ký không giữ tài liệu, chỉ giữ địa chỉ.

---

## 2. Data Node: Nơi lưu trữ dữ liệu (The Worker)

Data Node là các máy chủ lưu trữ thực tế, nơi dữ liệu được ghi xuống đĩa cứng.

### Khái niệm & Giải thích
Mỗi Data Node là một máy chủ độc lập chạy hệ điều hành Linux và hệ thống tệp tin cục bộ (như ext3, ext4, XFS).

**Các vai trò chính:**
*   **Lưu trữ Block:** Dữ liệu được chia thành các Block (ví dụ 128MB) và lưu trữ trên đĩa cứng cục bộ.
*   **Lưu Checksum:** Lưu trữ thông tin kiểm tra lỗi (CRC32) đi kèm với dữ liệu để đảm bảo tính toàn vẹn.
*   **Phục vụ Client:** Nhận yêu cầu đọc/ghi trực tiếp từ Client.
*   **Pipelining (Đường ống):** Khi ghi dữ liệu, Data Node nhận dữ liệu và chuyển tiếp ngay lập tức sang Data Node tiếp theo trong chuỗi nhân bản.
*   **Báo cáo trạng thái:**
    *   **Block Report:** Định kỳ gửi danh sách các Block đang giữ cho Name Node.
    *   **Heartbeat (Nhịp đập):** Cứ mỗi **3 giây**, Data Node gửi tín hiệu "tôi vẫn sống" lên Name Node.

### Ưu & Nhược điểm
| Tiêu chí | Chi tiết |
| :--- | :--- |
| **Ưu điểm** | - **Tính mở rộng (Scalability):** Dễ dàng thêm máy chủ mới để tăng dung lượng lưu trữ.<br>- **Chi phí thấp:** Sử dụng phần cứng thương mại (COTS - Commercial Off-The-Shelf). |
| **Nhược điểm** | - **Phụ thuộc vào Name Node:** Không thể hoạt động độc lập nếu không kết nối được với Name Node. |

### Ví dụ thực tế
Giả sử bạn có 100 máy chủ vật lý trong trung tâm dữ liệu. Mỗi máy chủ này là một Data Node. Dữ liệu của bạn (ví dụ: 1 Petabyte video) được chia nhỏ và rải ra 100 máy chủ này. Nếu một máy chủ bị cháy, dữ liệu vẫn an toàn ở 99 máy còn lại nhờ cơ chế nhân bản.

---

## 3. Nhân bản dữ liệu (Data Replication)

Đây là cơ chế cốt lõi giúp HDFS chịu được lỗi phần cứng.

### Giải thích chi tiết
HDFS sao chép mỗi Block dữ liệu (thường là 3 bản) lên các Data Node khác nhau để phòng ngừa sự cố.

**Chiến lược đặt chỗ (Placement Policy):**
Đây là thuật toán thông minh để tối ưu hóa tốc độ đọc và độ an toàn:
1.  **Replica 1:** Đặt trên **Node đích** (nếu Client nằm trong cụm) hoặc một Node ngẫu nhiên (nếu Client nằm ngoài cụm) để tối ưu ghi.
2.  **Replica 2:** Đặt trên một **Rack (tủ rack) khác** (tủ rack là nhóm các máy chủ chung một switch mạng). Mục đích để phòng ngừa lỗi cả một tủ rack.
3.  **Replica 3:** Đặt trên **cùng Rack với Replica 2**. Mục đích để tăng tốc độ đọc (giảm băng thông cross-rack) nhưng vẫn an toàn hơn Replica 1.
4.  **Replica > 3:** Đặt ngẫu nhiên trên các Rack còn lại.

**Hoạt động khi lỗi:**
*   Khi Name Node không nhận được Heartbeat từ Data Node A trong một khoảng thời gian, nó coi Data Node A đã chết.
*   Name Node sẽ tìm tất cả các Block có bản sao duy nhất trên Data Node A và yêu cầu các Data Node khác sao chép lại để đảm bảo số lượng nhân bản (ví dụ: về lại mức 3).

### Ví dụ thực tế
Một công ty điện ảnh lưu trữ phim 4K. Block phim được chia làm 3 bản:
*   Bản 1: Lưu ở Server 1 (Tủ Rack 1).
*   Bản 2: Lưu ở Server 5 (Tủ Rack 2).
*   Bản 3: Lưu ở Server 6 (Cùng Tủ Rack 2).
Nếu Server 1 bị lỗi, dữ liệu vẫn an toàn. Nếu cả Tủ Rack 2 bị mất điện, dữ liệu vẫn an toàn nhờ Server 1.

---

## 4. Tái nhân bản dữ liệu (Rebalancing)

### Giải thích chi tiết
Quá trình này diễn ra khi cấu trúc cụm lưu trữ thay đổi.

**Mục tiêu:**
*   **Cân bằng dung lượng:** Đảm bảo các Data Node có tỷ lệ % dung lượng đĩa sử dụng tương đương nhau.
*   **Cân bằng kết nối:** Tránh để một vài node quá tải trong khi node khác rảnh rỗi.

**Khi nào thực hiện:**
*   Khi một **Data Node mới** được thêm vào cụm (ví dụ: mở rộng dung lượng từ 100TB lên 150TB). Dữ liệu sẽ được di chuyển từ các node cũ sang node mới để cân bằng.
*   Khi một Data Node bị đầy.

**Đặc điểm:**
*   Quá trình chạy nền (background), không ảnh hưởng đến hoạt động đọc/ghi của người dùng.
*   Có thể điều chỉnh tốc độ để tránh nghẽn mạng.
*   Có thể kích hoạt thủ công bằng dòng lệnh.

### Ví dụ thực tế
Bạn mua thêm 10 máy chủ mới để tăng dung lượng lưu trữ. Ban đầu, 10 máy này rỗng hoàn toàn. HDFS sẽ tự động (hoặc管理员 chạy lệnh) di chuyển các Block dữ liệu từ 10 máy cũ sang 10 máy mới để phân bổ đều.

---

## 5. Đảm bảo tính đúng đắn của dữ liệu (Data Integrity)

### Giải thích chi tiết
Dữ liệu có thể bị hỏng do lỗi phần cứng (bad sector, bit rot) trong quá trình lưu trữ hoặc truyền tải. HDFS sử dụng **Checksum** để phát hiện điều này.

**Cơ chế hoạt động:**
*   **Thuật toán:** **CRC32** (Cyclic Redundancy Check).
*   **Kích thước:** Mỗi Block dữ liệu (ví dụ 128MB) được chia thành các phần nhỏ (ví dụ 512 bytes). Với mỗi phần này, một checksum được tính toán và lưu riêng.

**Quy trình kiểm tra (Read Path):**
1.  **Khởi tạo (Write):** Client tính toán checksum khi ghi dữ liệu. Gửi dữ liệu + checksum đến Data Node. Data Node lưu cả 2.
2.  **Truy cập (Read):**
    *   Client yêu cầu đọc dữ liệu từ Data Node.
    *   Client nhận được **dữ liệu** và **checksum**.
    *   Client tự tính toán checksum lại trên dữ liệu vừa nhận.
    *   So sánh checksum tính toán vs checksum nhận được.
    *   **Nếu khớp:** Dữ liệu đúng.
    *   **Nếu không khớp:** Dữ liệu bị lỗi. Client sẽ thử lấy dữ liệu từ một **Replica (nhân bản)** khác trên Data Node khác.

### Ví dụ thực tế
Khi bạn tải một file cài đặt Windows từ internet, đôi khi bạn thấy dòng chữ "Verifying download..." hoặc file có đuôi `.md5`/`.sha1`. Đó chính là đang kiểm tra checksum. HDFS làm việc này tự động ở mức độ Block dữ liệu.

---

## 6. Mã giả & Ví dụ Code Mẫu

Dưới đây là các đoạn mã minh họa cho các quy trình logic trong HDFS.

### A. Logic Hoạt động của Name Node (Pseudo-code)

Đoạn code này mô tả cách Name Node xử lý Heartbeat và quản lý lỗi.

```python
class NameNode:
    def __init__(self):
        self.metadata = {}  # Ánh xạ: {filename: [block_ids]}
        self.block_map = {} # Ánh xạ: {block_id: [datanode_ids]}
        self.datanode_status = {} # Trạng thái sống/chết

    def receive_heartbeat(self, datanode_id, block_report):
        """
        Nhận heartbeat từ Data Node (cứ 3s một lần)
        """
        self.datanode_status[datanode_id] = "ALIVE"
        
        # Cập nhật Block Report (danh sách block đang lưu trữ)
        for block_id in block_report:
            if block_id not in self.block_map:
                self.block_map[block_id] = []
            if datanode_id not in self.block_map[block_id]:
                self.block_map[block_id].append(datanode_id)

    def check_node_failure(self):
        """
        Kiểm tra định kỳ xem node nào đã chết
        """
        dead_nodes = []
        for node, status in self.datanode_status.items():
            if status == "DEAD": # Logic kiểm tra timeout ở đây
                dead_nodes.append(node)
        
        for node in dead_nodes:
            self.trigger_replication(node)

    def trigger_replication(self, dead_node):
        """
        Kích hoạt tái nhân bản cho các block bị mất
        """
        print(f"Phát hiện Data Node {dead_node} lỗi. Bắt đầu tái nhân bản...")
        for block_id, nodes in self.block_map.items():
            if dead_node in nodes:
                nodes.remove(dead_node)
                # Chọn Data Node mới để sao chép
                new_node = self.select_best_node()
                if new_node:
                    self.block_map[block_id].append(new_node)
                    print(f"Block {block_id} sẽ được nhân bản lên {new_node}")
```

### B. Logic Kiểm tra Tính toàn vẹn Dữ liệu (Client Side)

```python
import zlib
import hashlib

def verify_data_integrity(data_block, received_checksum):
    """
    Client tự tính toán checksum và so sánh với checksum từ Data Node
    """
    # Tính CRC32 trên block dữ liệu (giả lập)
    calculated_checksum = zlib.crc32(data_block) & 0xffffffff
    
    # So sánh (Trong thực tế HDFS dùng checksum khác, nhưng logic tương tự)
    if calculated_checksum == received_checksum:
        return True
    else:
        return False

# Ví dụ sử dụng
data = b"This is a sample data block for HDFS..."
checksum = zlib.crc32(data) & 0xffffffff

# Giả lập Data Node trả về sai dữ liệu (bị lỗi bit)
corrupted_data = b"This is a sample data blOck for HDFS..." # Chữ 'o' thành 'O'

if verify_data_integrity(corrupted_data, checksum):
    print("Dữ liệu hợp lệ.")
else:
    print("Dữ liệu bị lỗi! Yêu cầu lấy từ Replica khác.")
```

### C. Command Line (HDFS Shell)

Đây là cách người quản trị viên tương tác để kiểm tra và tái nhân bản.

```bash
# 1. Xem cấu trúc tệp tin và trạng thái nhân bản
hdfs dfs -ls -h /user/hive/warehouse

# 2. Kích hoạt tái nhân bản (Rebalance) thủ công
# Thường dùng khi thêm node mới hoặc trước khi bảo trì
hdfs balancer -threshold 10
# (Threshold 10%: Cân bằng khi chênh lệch dung lượng giữa các node > 10%)

# 3. Kiểm tra checksum của một file trên HDFS
hdfs dfs -checksum /user/data/large_file.log

# 4. Xem thông tin chi tiết về một Block cụ thể
hdfs fsck /user/data/large_file.log -files -blocks -locations
```

---

## Tóm tắt tổng quan

| Thành phần | Tên tiếng Anh | Vai trò chính | Tần suất hoạt động |
| :--- | :--- | :--- | :--- |
| **Name Node** | Master | Quản lý Metadata, Namespace, điều phối Replication | Liên tục |
| **Data Node** | Worker | Lưu trữ Block, gửi Heartbeat | Liên tục (3s Heartbeat) |
| **Replication** | Replication | Sao chép dữ liệu (Default 3x) để chống lỗi | Khi ghi dữ liệu / Khi lỗi |
| **Rebalancing** | Rebalancing | Cân bằng dữ liệu khi thêm node mới | Khi có thay đổi cấu hình |
| **Checksum** | CRC32 | Đảm bảo dữ liệu không bị hỏng bit | Khi ghi và khi đọc |

---


> [Lỗi xử lý trang 11-15]

> [Lỗi xử lý trang 16-20]
Chào bạn, với vai trò là một chuyên gia về Big Data và Hệ thống Phân tán, tôi sẽ phân tích và trình bày lại nội dung tài liệu slide "3.3_HDFS_vn.pdf" một cách chi tiết, chuyên nghiệp và dễ hiểu theo đúng yêu cầu của bạn.

---

# Các Giao diện và Định dạng Dữ liệu trong HDFS (Hadoop Distributed File System)

Bên cạnh các giao diện cốt lõi, HDFS cung cấp nhiều phương thức tương tác và hỗ trợ đa dạng các định dạng dữ liệu để tối ưu hóa cho các tác vụ Big Data. Việc lựa chọn định dạng phù hợp là yếu tố then chốt quyết định hiệu suất của toàn bộ hệ thống.

## 1. Các Giao diện Khác của HDFS (Other HDFS Interfaces)

HDFS không chỉ giới hạn ở một cách thức truy cập duy nhất. Nó cung cấp nhiều API và giao thức linh hoạt để tích hợp với các hệ thống và ngôn ngữ lập trình khác nhau.

### 1.1. Java API
Đây là giao diện gốc và mạnh mẽ nhất, được sử dụng để tương tác trực tiếp với HDFS từ các ứng dụng Java.

-   **Khi nào sử dụng?**
    -   Khi phát triển các ứng dụng Java/Scala/JVM-based để xử lý dữ liệu trực tiếp trên HDFS.
    -   Khi cần kiểm soát chi tiết các thao tác file (tạo, ghi, đọc, xóa, quản lý quyền).
-   **Sử dụng như thế nào?**
    -   Sử dụng thư viện `hadoop-common` và `hadoop-hdfs`.
    -   Khởi tạo đối tượng `FileSystem` và thực hiện các thao tác thông qua các API như `create()`, `open()`, `append()`.
-   **Ưu & Nhược điểm:**
    -   **Ưu:** Mạnh mẽ, đầy đủ tính năng, hiệu suất cao, kiểm soát tốt.
    -   **Nhược:** Chỉ dành cho môi trường JVM, phức tạp hơn so với các giao diện cấp cao hơn.

**Code Mẫu (Java):**
```java
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import java.io.BufferedWriter;
import java.io.OutputStreamWriter;

public class HdfsWriteExample {
    public static void main(String[] args) {
        try {
            Configuration conf = new Configuration();
            // Cấu hình URL của NameNode (ví dụ: hdfs://localhost:9000)
            conf.set("fs.defaultFS", "hdfs://localhost:9000");
            
            FileSystem fs = FileSystem.get(conf);
            Path filePath = new Path("/user/demo/test.txt");
            
            // Ghi dữ liệu vào file trên HDFS
            try (BufferedWriter br = new BufferedWriter(
                    new OutputStreamWriter(fs.create(filePath, true)))) {
                br.write("Hello HDFS from Java API!");
                br.newLine();
            }
            
            System.out.println("File written successfully!");
            fs.close();
        } catch (Exception e) {
            e.printStackTrace();
        }
    }
}
```

### 1.2. Thrift API
Thrift API cho phép các ứng dụng không phải Java (như Python, C++, PHP, Ruby) có thể giao tiếp với HDFS thông qua một dịch vụ proxy (thường là `HDFS Thrift Server`).

-   **Khi nào sử dụng?**
    -   Khi cần truy cập HDFS từ các ngôn ngữ lập trình không thuộc hệ sinh thái JVM.
    -   Khi cần một giao thức RPC (Remote Procedure Call) hiệu năng cao.
-   **Sử dụng như thế nào?**
    -   Khởi chạy `HDFS Thrift Server`.
    -   Sử dụng thư viện Thrift của ngôn ngữ mục tiêu để kết nối và gọi các hàm.
-   **Ưu & Nhược điểm:**
    -   **Ưu:** Ngôn ngữ độc lập, hiệu suất tốt.
    -   **Nhược:** Yêu cầu chạy thêm một dịch vụ trung gian (Thrift Server), phức tạp trong thiết lập.

### 1.3. FUSE (Filesystem in Userspace)
FUSE cho phép mounting HDFS như một hệ thống file cục bộ (local filesystem) trên máy Linux/Unix.

-   **Khi nào sử dụng?**
    -   Khi muốn truy cập dữ liệu HDFS như một thư mục cục bộ thông qua lệnh `ls`, `cp`, `cat`...
    -   Khi cần tích hợp HDFS với các công cụ dòng lệnh chuẩn của Linux.
-   **Sử dụng như thế nào?**
    -   Sử dụng thư viện `hadoop-hdfs-fuse` hoặc `fuse-dfs`.
    -   Chạy lệnh mount: `hdfs dfs -mount ...`
-   **Ưu & Nhược điểm:**
    -   **Ưu:** Tiện lợi, dễ sử dụng cho người dùng hệ thống.
    -   **Nhược:** Hiệu suất không tốt bằng API Java, không hỗ trợ đầy đủ các thuộc tính file của POSIX.

### 1.4. WebDAV
WebDAV (Web Distributed Authoring and Versioning) là một giao thức HTTP mở rộng cho phép quản lý file trên server từ xa.

-   **Khi nào sử dụng?**
    -   Khi cần truy cập HDFS từ các công cụ hỗ trợ WebDAV (như Windows Explorer, macOS Finder, hay các trình duyệt web).
    -   Khi cần một giao thức chuẩn web để truy cập dữ liệu.
-   **Sử dụng như thế nào?**
    -   Kích hoạt WebDAV trong cấu hình NameNode.
    -   Truy cập qua URL `http://<namenode>:50070/webhdfs/v1/...`
-   **Ưu & Nhược điểm:**
    -   **Ưu:** Tương thích cao, dễ truy cập từ các trình duyệt/công cụ có sẵn.
    -   **Nhược:** Hiệu suất thấp, không phù hợp cho các tác vụ xử lý dữ liệu khối lượng lớn.

---

## 2. Các Định dạng Dữ liệu trong HDFS (HDFS Data Formats)

Việc chọn định dạng dữ liệu phù hợp ảnh hưởng trực tiếp đến khả năng nén, tốc độ truy vấn và hiệu suất xử lý song song (parallel processing).

### 2.1. Định dạng Văn bản (Text File)

Đây là định dạng cơ bản nhất, bao gồm CSV, TSV, JSON.

-   **Đặc điểm:**
    -   Dễ dàng trao đổi giữa các ứng dụng, script.
    -   **Human-readable** (dễ đọc bởi người).
    -   **Không hỗ trợ nén theo block (block compression)**: Nếu nén toàn file, HDFS không thể chia nhỏ (split) file để xử lý song song.
    -   Không hiệu quả để truy vấn (phải parse toàn bộ dữ liệu).

-   **Khi nào sử dụng?**
    -   Dữ liệu đầu vào/thông qua (staging).
    -   Dữ liệu nhỏ, cần kiểm tra thủ công.
    -   Chia sẻ dữ liệu với các hệ thống ngoài Hadoop.
-   **Sử dụng như thế nào?**
    -   Sử dụng `TextInputFormat` trong MapReduce hoặc `spark.read.text()` trong Spark.
-   **Ưu & Nhược điểm:**
    -   **Ưu:** Đơn giản, phổ biến, dễ debug.
    -   **Nhược:** Kém hiệu quả về dung lượng (không nén), kém hiệu suất truy vấn, không splittable nếu nén gzip.

**Code Mẫu (Tạo file Text bằng Shell):**
```bash
# Tạo một file CSV cục bộ
echo "id,name,age" > data.csv
echo "1,John,30" >> data.csv
echo "2,Jane,25" >> data.csv

# Đẩy lên HDFS
hdfs dfs -mkdir -p /user/demo/input
hdfs dfs -put data.csv /user/demo/input/
```

### 2.2. Sequence File

SequenceFile là một cấu trúc dữ liệu nhị phân bền vững cho các cặp key-value.

-   **Đặc điểm:**
    -   **Row-based** (dựa trên hàng).
    -   **Hỗ trợ nén (Compression):** Có thể nén theo từng block riêng lẻ.
    -   **Splittable:** Có thể chia nhỏ file để xử lý song song ngay cả khi đã nén.
    -   Thường được dùng để chuyển dữ liệu giữa các job MapReduce hoặc lưu trữ các file nhỏ (pack small files).

-   **Khi nào sử dụng?**
    -   Khi cần lưu trữ dữ liệu nhị phân dưới dạng key-value.
    -   Để lưu trữ output của các job MapReduce.
    -   Để gộp nhiều file nhỏ (small files) thành một file lớn để tối ưu NameNode.
-   **Sử dụng như thế nào?**
    -   Sử dụng `SequenceFileInputFormat` / `SequenceFileOutputFormat` trong MapReduce.
-   **Ưu & Nhược điểm:**
    -   **Ưu:** Tối ưu cho MapReduce, nén tốt, splittable.
    -   **Nhược:** Chỉ hỗ trợ định dạng key-value, không linh hoạt bằng Avro/Parquet.

**Code Mẫu (Java - Ghi SequenceFile):**
```java
// Pseudo-code minh họa cấu trúc
Configuration conf = new Configuration();
FileSystem fs = FileSystem.get(conf);
Path path = new Path("hdfs://path/to/seqfile.seq");

// Key và Value class
Class keyClass = Text.class;
Class valueClass = IntWritable.class;

SequenceFile.Writer writer = SequenceFile.createWriter(fs, conf, path, keyClass, valueClass);

writer.append(new Text("user1"), new IntWritable(100));
writer.append(new Text("user2"), new IntWritable(200));
writer.close();
```

### 2.3. Apache Avro

Avro là một hệ thống serialization dữ liệu ngang hàng (peer-to-peer) cung cấp các định dạng nhị phân giàu cấu trúc.

-   **Đặc điểm:**
    -   **Row-based**.
    -   **Hỗ trợ nén đối tượng và Splittable.**
    -   **Linh hoạt về Schema:** Schema (định nghĩa dữ liệu) được lưu trữ trong file header dưới dạng JSON.
    -   Hỗ trợ các kiểu dữ liệu phức tạp (record, array, map).
    -   Hỗ trợ serialization nhị phân và JSON.

-   **Khi nào sử dụng?**
    -   Khi cần lưu trữ dữ liệu có cấu trúc phức tạp.
    -   Khi dữ liệu cần tiến hóa (thêm/xóa trường) mà không làm hỏng các job cũ.
    -   Làm định dạng chuẩn cho Kafka, HBase.
-   **Sử dụng như thế nào?**
    -   Định nghĩa schema `.avsc`.
    -   Sử dụng thư viện Avro để ghi/đọc dữ liệu.
-   **Ưu & Nhược điểm:**
    -   **Ưu:** Linh hoạt schema, hiệu suất cao, hỗ trợ đa ngôn ngữ.
    -   **Nhược:** Đọc ngẫu nhiên (random read) kém hiệu quả hơn columnar formats.

**Code Mẫu (Avro Schema - `user.avsc`):**
```json
{
  "type": "record",
  "name": "User",
  "fields": [
    {"name": "name", "type": "string"},
    {"name": "age",  "type": "int"}
  ]
}
```

### 2.4. Parquet & ORC (Optimized Row Columnar)

Cả hai đều là định dạng **Columnar** (Cột), lưu trữ dữ liệu theo cột thay vì theo hàng.

#### Parquet
-   **Đặc điểm:** Tối ưu hóa cho các truy vấn phức tạp, nén cực tốt (cùng kiểu dữ liệu trong cùng một cột), hỗ trợ nhiều công cụ (Hive, Impala, Spark).

#### ORC (Optimized Row Columnar)
-   **Đặc điểm:** Được tối ưu hóa riêng cho Hive, nén tốt hơn Parquet trong một số trường hợp, hỗ trợ Indexes và Statistics (Min/Max/Sum).

-   **Khi nào sử dụng?**
    -   Khi cần truy vấn các cột cụ thể trong bảng dữ liệu lớn (Data Warehouse).
    -   Khi cần tối ưu dung lượng lưu trữ và tốc độ đọc (OLAP).
-   **Sử dụng như thế nào?**
    -   Trong Hive: `STORED AS PARQUET` hoặc `STORED AS ORC`.
    -   Trong Spark: `spark.read.parquet(...)` hoặc `spark.read.orc(...)`.
-   **Ưu & Nhược điểm:**
    -   **Ưu:** Nén cao, đọc nhanh (chỉ đọc các cột cần thiết), hỗ trợ Predicate Pushdown.
    -   **Nhược:** Ghi (write) chậm hơn do phức tạp, không phù hợp cho việc cập nhật (update) dữ liệu thường xuyên.

**Code Mẫu (HiveQL tạo bảng Parquet):**
```sql
CREATE TABLE users_parquet (
    name STRING,
    age INT
)
STORED AS PARQUET
LOCATION '/user/demo/users_parquet';

-- Chèn dữ liệu
INSERT INTO TABLE users_parquet VALUES ('Alice', 30), ('Bob', 25);
```

---

## 3. Tóm tắt So sánh

| Định dạng | Dạng lưu trữ | Nén | Splittable | Khi nào dùng? |
| :--- | :--- | :--- | :--- | :--- |
| **Text** | Row | Không (hoặc gzip không splittable) | Có (nếu không nén) | Dữ liệu thô, trao đổi đơn giản. |
| **SequenceFile** | Row | Có | Có | Chuyển dữ liệu MapReduce, gộp file nhỏ. |
| **Avro** | Row | Có | Có | Dữ liệu phức tạp, cần thay đổi schema. |
| **Parquet** | Column | Rất tốt | Có | Data Warehouse, truy vấn nhanh theo cột. |
| **ORC** | Column | Rất tốt | Có | Tối ưu cho Hive, lưu trữ tối ưu. |

---

Chào bạn, tôi là chuyên gia về Big Data và Hệ thống Phân tán. Dưới đây là phân tích chi tiết về các định dạng file trong hệ sinh thái Hadoop (Avro, Parquet, ORC) dựa trên nội dung slide bạn cung cấp, được trình bày chuyên nghiệp bằng Markdown.

---

# Phân tích Định dạng File trong Hệ sinh thái Hadoop: Avro, Parquet, và ORC

Trong bối cảnh xử lý Big Data, việc lựa chọn định dạng file (File Format) phù hợp là yếu tố then chốt quyết định hiệu suất, khả năng lưu trữ và độ linh hoạt của hệ thống. Ba định dạng phổ biến nhất trong hệ sinh thái Hadoop là **Avro**, **Parquet**, và **ORC**. Mỗi loại đều có cấu trúc, ưu điểm và mục đích sử dụng riêng.

---

## 1. Avro: Định dạng Dựa trên Schema

**Avro** là một hệ thống serialization dữ liệu mã nguồn mở, cung cấp các định dạng dữ liệu nhị phân紧凑 (compact) và JSON dễ đọc. Nó đặc biệt phù hợp cho việc ghi dữ liệu trong các hệ thống streaming (như Kafka).

### Giải thích Khái niệm
*   **Schema-driven:** Avro lưu trữ schema (cấu trúc dữ liệu) trong file dữ liệu. Điều này cho phép các chương trình đọc file mà không cần định nghĩa trước cấu trúc dữ liệu.
*   **Dynamic Typing:** Không giống như các hệ thống serialization nhị phân khác (như Thrift hay Protobuf), Avro không cần tạo mã (code generation) trước khi ghi hoặc đọc dữ liệu.
*   **Structure:** Dữ liệu được đóng gói theo từng block, mỗi block chứa số lượng bản ghi và kích thước block. Schema thường được lưu ở đầu file hoặc khi bắt đầu giao dịch (handshake).

### Cấu trúc File & Code Mẫu

Dựa trên slide, đây là một ví dụ về **Avro Schema** định nghĩa một tweet:

```json
{
  "type": "record",
  "name": "tweets",
  "fields": [
    {
      "name": "username",
      "type": "string"
    },
    {
      "name": "tweet",
      "type": "string"
    },
    {
      "name": "timestamp",
      "type": "long"
    }
  ],
  "doc": "schema for storing tweets"
}
```

**Code Mẫu (Python sử dụng library `fastavro`):**

```python
from fastavro import writer, reader
import io

# 1. Định nghĩa Schema
schema = {
    "type": "record",
    "name": "tweets",
    "fields": [
        {"name": "username", "type": "string"},
        {"name": "tweet", "type": "string"},
        {"name": "timestamp", "type": "long"}
    ]
}

# 2. Dữ liệu mẫu
records = [
    {"username": "user01", "tweet": "Hello Hadoop!", "timestamp": 1678886400},
    {"username": "data_guru", "tweet": "Avro is cool", "timestamp": 1678886405}
]

# 3. Ghi dữ liệu vào file Avro (hoặc buffer)
buffer = io.BytesIO()
writer(buffer, schema, records)

# 4. Đọc dữ liệu từ file Avro
buffer.seek(0)
for record in reader(buffer):
    print(record)
```

### Hướng dẫn Sử dụng
*   **Khi nào sử dụng?**
    *   Hệ thống Streaming (Apache Kafka, AWS Kinesis).
    *   Dữ liệu thay đổi cấu trúc thường xuyên (Schema Evolution).
    *   Khi cần giao tiếp giữa các dịch vụ (RPC).
*   **Sử dụng như thế nào?**
    *   Sử dụng các thư viện như `avro` (Java), `fastavro` (Python) để serialize/deserialize dữ liệu.
    *   Đảm bảo schema được đồng bộ giữa Producer và Consumer.
*   **Ưu & Nhược điểm:**
    *   **Ưu:** Linh hoạt (dễ thêm/xóa trường), lưu trữ schema tích hợp, hỗ trợ tốt cho Schema Evolution.
    *   **Nhược:** Không tối ưu cho việc truy vấn cột (columnar query) như Parquet, do dữ liệu được lưu theo hàng (row-based).

---

## 2. Parquet: Định dạng Cột (Columnar)

**Parquet** là một định dạng file nhị phân **column-oriented** được thiết kế để tối ưu hóa hiệu suất I/O đĩa, đặc biệt khi làm việc với các khối lượng dữ liệu lớn.

### Giải thích Khái niệm
*   **Columnar Storage:** Thay vì lưu dữ liệu theo hàng (ví dụ: `x1 y1 z1`, `x2 y2 z2`), Parquet lưu theo cột (ví dụ: `x1 x2 x3...`, `y1 y2 y3...`).
*   **Tại sao hiệu quả?** Khi bạn truy vấn một vài cột (ví dụ: chỉ lấy `username`), hệ thống chỉ cần đọc block dữ liệu của cột đó, bỏ qua các cột còn lại. Điều này giảm thiểu I/O đĩa đáng kể.
*   **Nested Columns:** Hỗ trợ các cấu trúc dữ liệu lồng nhau (nested) thông qua kỹ thuật mã hóa Dremel.
*   **Compression & Splitting:** Dễ dàng nén dữ liệu (vì dữ liệu同 loại trong một cột thường giống nhau) và chia nhỏ file để xử lý song song (parallel processing).

### Minh họa Cấu trúc

Slide minh họa sự khác biệt giữa lưu trữ Row và Columnar:

*   **Row Format:** `x1 y1 z1 | x2 y2 z2 | x3 y3 z3...` (Phải đọc toàn bộ record dù chỉ cần 1 field).
*   **Columnar Format:** `x1 x2 x3... | y1 y2 y3... | z1 z2 z3...` (Chỉ đọc cột cần thiết).

### Cấu trúc File & Cấu hình

Parquet cho phép cấu hình các tham số để tối ưu hóa lưu trữ và truy vấn.

| Thuộc tính (Property) | Giá trị mặc định | Mô tả |
| :--- | :--- | :--- |
| `parquet.block.size` | 128 MB | Kích thước byte của một block (row group). |
| `parquet.page.size` | 1 MB | Kích thước byte của một trang (đơn vị I/O cơ bản). |
| `parquet.dictionary.page.size` | 1 MB | Kích thước tối đa của từ điển trước khi chuyển về mã hóa thường. |
| `parquet.enable.dictionary` | `true` | Có sử dụng mã hóa từ điển hay không (tốt cho cột có nhiều giá trị lặp lại). |
| `parquet.compression` | `UNCOMPRESSED` | Loại nén: `UNCOMPRESSED`, `SNAPPY`, `GZIP`, `LZO`. |

**Code Mẫu (Python sử dụng `pyarrow`):**

```python
import pyarrow as pa
import pyarrow.parquet as pq
import pandas as pd

# Tạo dữ liệu mẫu
data = {
    'username': ['user01', 'user02', 'user03', 'user04', 'user05'],
    'tweet': ['Hello', 'Big Data', 'Parquet', 'Columnar', 'Storage'],
    'timestamp': [100, 101, 102, 103, 104]
}
df = pd.DataFrame(data)

# Chuyển đổi sang Table của Arrow
table = pa.Table.from_pandas(df)

# Ghi file Parquet với cấu hình nén Snappy
pq.write_table(
    table, 
    'tweets.parquet',
    compression='snappy',      # Nén dữ liệu
    row_group_size=5           # Chia thành các row group nhỏ
)

# Đọc dữ liệu (chỉ đọc cột 'username')
dataset = pq.ParquetFile('tweets.parquet')
for batch in dataset.iter_batches(columns=['username']):
    print(batch)
```

### Hướng dẫn Sử dụng
*   **Khi nào sử dụng?**
    *   Phân tích dữ liệu (Data Analytics), OLAP (Online Analytical Processing).
    *   Khi làm việc với các file dữ liệu lớn (Big Data) và cần truy vấn nhanh trên các cột cụ thể.
    *   Các công cụ như Spark, Hive, Presto, Athena.
*   **Sử dụng như thế nào?**
    *   Sử dụng các thư viện như `pyarrow`, `pandas` (Python) hoặc `Spark SQL`.
    *   Chọn phương pháp nén phù hợp (Snappy thường dùng cho tốc độ, GZIP cho tỷ lệ nén cao).
*   **Ưu & Nhược điểm:**
    *   **Ưu:** Tối ưu I/O, tỷ lệ nén cao, hỗ trợ Predicate Pushdown (lọc dữ liệu ở mức file), tách biệt cấu trúc lưu trữ và cấu trúc dữ liệu.
    *   **Nhược:** Việc ghi (write) phức tạp hơn do phải sắp xếp dữ liệu theo cột; không tối ưu cho các tác vụ ghi nhiều (write-heavy).

---

## 3. ORC (Optimized Row Columnar): Nâng cao từ RCFile

**ORC** (Optimized Row Columnar) là định dạng được phát triển bởi Hortonworks (nay là Cloudera) để cải thiện hiệu suất so với định dạng **RCFile** (Row Columnar File) cũ hơn.

### Giải thích Khái niệm
*   **Tiến hóa từ RCFile:** RCFile nén từng cột trong một row group, nhưng ORC đi xa hơn với **Block-mode compression** và lưu trữ theo cấu trúc Stripe (dải).
*   **Cấu trúc Stripe:** File ORC được chia thành các Stripe (dải) lớn. Trong mỗi Stripe, dữ liệu được lưu trữ theo định dạng cột (columnar).
*   **Lightweight Indexing:** ORC tạo chỉ mục (index) nhẹ trong mỗi Stripe. Nó lưu các giá trị tối thiểu (min), tối đa (max), và tổng hợp (sum, count). Nhờ đó, khi truy vấn, nó có thể **bỏ qua (skip)** các block hàng không liên quan mà không cần đọc toàn bộ dữ liệu.
*   **Splittable:** File có thể được chia nhỏ để xử lý song song trên các node phân tán.

### Minh họa Cấu trúc
*   **RCFile:** Nén theo cột nhưng chưa tối ưu cấu trúc lưu trữ.
*   **ORC File:**
    *   **Stripe:** Chứa dữ liệu thực tế (lưu trữ theo cột).
    *   **Index:** Chứa thông tin tóm tắt (min, max, count) cho phép tìm kiếm nhanh.
    *   **Footer:** Chứa metadata và thông tin về cấu trúc file.

### Code Mẫu (Hive/SQL)

ORC thường được sử dụng trong Hive hoặc Spark SQL. Dưới đây là ví dụ tạo bảng sử dụng định dạng ORC trong Hive:

```sql
CREATE TABLE tweets_orc (
    username STRING,
    tweet STRING,
    timestamp BIGINT
)
STORED AS ORC
TBLPROPERTIES (
    "orc.compress" = "ZLIB",       -- Phương pháp nén (ZLIB, SNAPPY, NONE)
    "orc.create.index" = "true"    -- Bật chỉ mục để skip blocks
);

-- Chèn dữ liệu (giả định)
INSERT INTO TABLE tweets_orc VALUES 
('user01', 'ORC is fast', 1678886400),
('user02', 'Columnar format', 1678886405);

-- Truy vấn: Nhờ index, ORC có thể bỏ qua các Stripe không chứa 'user01'
SELECT * FROM tweets_orc WHERE username = 'user01';
```

### Hướng dẫn Sử dụng
*   **Khi nào sử dụng?**
    *   Hệ thống Data Warehouse sử dụng Hive hoặc Spark.
    *   Khi cần độ nén cao và tốc độ truy vấn nhanh trên các bảng lớn.
    *   Khi cần các chỉ mục phức tạp (min/max) để tối ưu hóa truy vấn.
*   **Sử dụng như thế nào?**
    *   Sử dụng `STORED AS ORC` trong Hive/Spark SQL.
    *   Cấu hình các thuộc tính nén và chỉ mục.
*   **Ưu & Nhược điểm:**
    *   **Ưu:** Tỷ lệ nén rất cao (thường tốt hơn Parquet), hỗ trợ chỉ mục (Index) để bỏ qua dữ liệu không cần thiết, hỗ trợ các kiểu dữ liệu phức tạp.
    *   **Nhược:** Ít linh hoạt hơn Avro về mặt Schema Evolution; chủ yếu tối ưu cho Hive/Spark.

---

## Tóm tắt So sánh & Ví dụ Thực tế

| Đặc điểm | Avro | Parquet | ORC |
| :--- | :--- | :--- | :--- |
| **Loại định dạng** | Row-based (Binary) | Columnar | Columnar (Optimized) |
| **Lưu trữ Schema** | Trong file (JSON) | Trong Footer | Trong Footer |
| **Tối ưu cho** | Streaming, Write-heavy | Analytics, Read-heavy | Hive, Data Warehouse |
| **Hỗ trợ Index** | Không | Không (mặc định) | Có (Min/Max/Count) |
| **Compression** | Có | Tốt (Page-level) | Rất tốt (Block-level) |

### Ví dụ Thực tế trong Ngành

1.  **Avro trong hệ thống Recommendation (E-commerce):**
    *   *Kịch bản:* Khi người dùng click vào sản phẩm, sự kiện được đẩy vào Kafka.
    *   *Tại sao dùng Avro?* Dữ liệu click có thể thay đổi (thêm trường `device_type`, `session_id`). Avro cho phép thêm trường mới mà không làm hỏng các consumer cũ. Dữ liệu được lưu vào HDFS/S3 ở dạng Avro để xử lý batch sau đó.

2.  **Parquet trong Phân tích Bán hàng (Retail):**
    *   *Kịch bản:* Công ty có bảng dữ liệu giao dịch với hàng tỷ dòng và hàng trăm cột (Product ID, Price, Quantity, Region, Date...).
    *   *Tại sao dùng Parquet?* Khi báo cáo cần tính toán tổng doanh thu theo Region và Date, Parquet chỉ cần đọc 3 cột đó, bỏ qua hàng trăm cột khác, giảm thời gian query từ hàng giờ xuống vài phút.

3.  **ORC trong Data Warehouse (Telco):**
    *   *Kịch bản:* Nhà mạng lưu trữ logs cuộc gọi (Call Detail Records - CDR) để tính cước và phân tích.
    *   *Tại sao dùng ORC?* Cần độ nén cao để tiết kiệm dung lượng lưu trữ khổng lồ. Sử dụng Hive để truy vấn, ORC với khả năng skip Stripe không cần thiết giúp tăng tốc độ truy vấn dữ liệu lịch sử.

---

Chân thành cảm ơn bạn đã theo dõi! Hy vọng tài liệu này giúp bạn hiểu rõ sâu sắc về các định dạng file quan trọng trong Big Data.

---

