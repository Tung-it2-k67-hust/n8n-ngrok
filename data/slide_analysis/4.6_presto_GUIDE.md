# Phân tích chi tiết: 4.6_presto.pdf

Dưới đây là tài liệu được phân tích và trình bày lại chi tiết theo yêu cầu của bạn, tập trung vào hệ thống **Presto** (nay là **Trino**) dựa trên các slide được cung cấp.

***

# Phân tích & Tổng quan về Presto (Interactive SQL Query Engine)

## 1. Giới thiệu & Lịch sử hình thành (History)

**Presto** là một hệ thống query engine phân tán được thiết kế để chạy truy vấn SQL trên các nguồn dữ liệu lớn (Big Data) với tốc độ cực nhanh. Ban đầu nó được phát triển bởi Facebook (nay là Meta) để giải quyết các vấn đề về hiệu năng khi xử lý lượng dữ liệu khổng lồ.

### Timeline phát triển chính:
*   **Mùa thu 2012 (2012 Fall):** Dự án bắt đầu tại Facebook.
    *   **Mục tiêu:** Thiết kế cho các truy vấn tương tác (Interactive Query).
    *   **Yêu cầu:** Tốc độ của hệ thống Data Warehouse thương mại (như Oracle, Teradata) nhưng có khả năng mở rộng (Scalability) đến quy mô dữ liệu của Facebook.
*   **Mùa đông 2013 (2013 Winter):** Facebook chính thức open-source Presto.
    *   Chỉ sau 6 tháng đã có hơn 30 người đóng góp, bao gồm cả các lập trình viên ngoài Facebook.
*   **Năm 2019:** Cộng đồng phát triển mạnh mẽ với hơn 300 người đóng góp.
*   **Lưu ý:** Hiện tại, phiên bản mã nguồn mở chính thức được duy trì bởi dự án **Trino** (trước đây gọi là PrestoSQL).

---

## 2. Động lực phát triển (Motivation)

Tại sao Facebook cần tạo ra Presto? Họ gặp phải các vấn đề lớn với các công cụ hiện có tại thời điểm đó (như Hive).

### Các vấn đề cốt lõi:
1.  **Hive quá chậm:** Hive được thiết kế cho Batch Processing (xử lý hàng loạt), không phải cho các truy vấn tương tác (Interactive). Việc chạy một truy vấn qua Hive để vẽ Dashboard thường mất quá nhiều thời gian.
2.  **Kết nối ODBC không ổn định:** Các công cụ BI (Business Intelligence) kết nối trực tiếp vào HDFS thường không ổn định hoặc không khả dụng.
3.  **Chi phí & Tính mở rộng (Scalability):**
    *   Để có tốc độ nhanh, họ phải chuyển dữ liệu từ HDFS sang các database tương tác chuyên dụng như **PostgreSQL** hoặc **Redshift**.
    *   Điều này tốn kém chi phí lưu trữ và nhân bản dữ liệu (Data Duplication).
    *   Các database này cũng khó mở rộng quy mô (Scale out) bằng HDFS.
4.  **Dữ liệu nằm rải rác:** Một số dữ liệu không nằm trong HDFS, buộc phải sao chép vào HDFS để phân tích, gây phức tạp trong việc quản lý dữ liệu (Data Silos).

**=> Giải pháp Presto:** Cho phép truy vấn trực tiếp dữ liệu tại chỗ (In-place) trên nhiều nguồn dữ liệu khác nhau (HDFS, S3, MySQL, Cassandra...) mà không cần di chuyển dữ liệu, với tốc độ đủ nhanh cho các báo cáo trực tuyến.

---

## 3. Khái niệm & Giải thích (Concepts)

### 3.1. Architecture (Kiến trúc)
Presto sử dụng kiến trúc **Masters-Slaves** (hoặc Coordinator-Workers) phân tán.

*   **Coordinator:** Máy chủ chính, nhận запрос (SQL), phân tích, lập kế hoạch truy vấn (Query Plan) và phân bổ任务 cho các Worker.
*   **Workers:** Các máy con, thực thi các tác vụ (Task) được giao và xử lý dữ liệu.

### 3.2. Mô hình MPP (Massively Parallel Processing)
Presto chia nhỏ một truy vấn thành nhiều phần nhỏ và xử lý đồng thời trên nhiều node Worker. Điều này cho phép xử lý lượng dữ liệu khổng lồ trong thời gian ngắn.

### 3.3. Push Model
Trái ngược với Hive (sử dụng Pull Model thông qua MapReduce), Presto sử dụng **Push Model**. Dữ liệu được "đẩy" qua các pipeline xử lý liên tục mà không cần phải ghi xuống đĩa (Disk) ở mỗi giai đoạn. Điều này giảm thiểu độ trễ (Latency) đáng kể.

---

## 4. Code Mẫu & Cách sử dụng (Usage & Examples)

### 4.1. Cấu hình kết nối (Configuration)
Để sử dụng Presto, bạn cần cấu hình các **Connectors** để kết nối với các nguồn dữ liệu khác nhau.

**Ví dụ: Cấu hình kết nối với Hive (hive.properties)**
Đây là file cấu hình nằm trong thư mục `etc/catalog/` của Presto.

```properties
# Tên connector, dùng trong câu lệnh SQL như: hive.default.table
connector.name=hive-hadoop2
hive.metastore.uri=thrift://metastore-host:9083
hive.s3.aws-access-key=YOUR_ACCESS_KEY
hive.s3.aws-secret-key=YOUR_SECRET_KEY
hive.s3.endpoint=s3.amazonaws.com
```

### 4.2. Truy vấn SQL (SQL Querying)
Presto hỗ trợ cú pháp SQL chuẩn ANSI, rất quen thuộc với các Data Analyst.

**Ví dụ: Phân tích dữ liệu giao dịch**
Giả sử bạn có bảng `sales_data` trong Hive.

```sql
-- Lấy tổng doanh thu theo ngày trong tháng 10
SELECT 
    order_date, 
    SUM(amount) as total_revenue,
    COUNT(order_id) as total_orders
FROM 
    hive.default.sales_data
WHERE 
    order_date >= DATE '2023-10-01'
GROUP BY 
    order_date
ORDER BY 
    total_revenue DESC;
```

### 4.3. Truy vấn liên kết (Federated Query)
Đây là tính năng mạnh nhất của Presto: Join dữ liệu từ nhiều nguồn khác nhau.

```sql
-- Join dữ liệu từ Hive (dữ liệu thô) và MySQL (dữ liệu cấu hình/danh mục)
SELECT 
    u.name, 
    SUM(o.amount) 
FROM 
    hive.default.orders o
JOIN 
    mysql.production.users u ON o.user_id = u.id
GROUP BY 
    u.name;
```

---

## 5. Ưu & Nhược điểm (Pros & Cons)

| Tiêu chí | Ưu điểm (Advantages) | Nhược điểm (Disadvantages) |
| :--- | :--- | :--- |
| **Tốc độ** | **Tốc độ cao:** Phù hợp cho các truy vấn tương tác (Interactive), thường trả về kết quả trong vài giây đến vài phút. | **Không phải Database:** Presto không lưu trữ dữ liệu, nó chỉ là engine query. Do đó, nó không hỗ trợ UPDATE/DELETE (trừ một số phiên bản mới hỗ trợ Delta Lake/Iceberg). |
| **Tính mở rộng** | **Mở rộng dễ dàng:** Có thể thêm node Worker để tăng công suất xử lý mà không cần dừng hệ thống. | **Yêu cầu tài nguyên:** Cần nhiều bộ nhớ (RAM) và CPU để chạy hiệu quả. |
| **Tính năng** | **Federated Query:** Kết nối và join dữ liệu từ nhiều nguồn (Hive, Kafka, RDBMS, S3...) trong cùng một câu lệnh. | **Phụ thuộc vào Metastore:** Hiệu năng phụ thuộc lớn vào Hive Metastore và cấu trúc file (Small files problem). |
| **Sử dụng** | **Tiết kiệm chi phí:** Phân tích trực tiếp trên dữ liệu hiện có (Data Lake) không cần ETL sang Warehouse. | **Khó tuning:** Đòi hỏi kinh nghiệm để tối ưu hóa các truy vấn phức tạp. |

---

## 6. Ví dụ thực tế trong ngành công nghiệp (Real-world Use Cases)

### Case Study 1: Facebook (Social Media Analytics)
*   **Vấn đề:** Kỹ sư cần kiểm tra lỗi hoặc phân tích hành vi người dùng ngay lập tức trên hàng Petabyte dữ liệu log.
*   **Giải pháp:** Sử dụng Presto để chạy SQL trực tiếp trên file log lưu trữ trên HDFS/Hadoop.
*   **Kết quả:** Giảm thời gian chờ từ hàng giờ (dùng Hive/MapReduce) xuống còn vài phút, giúp tăng tốc độ phát triển và sửa lỗi.

### Case Study 2: E-commerce (Big Data Analytics)
*   **Vấn đề:** Một công ty thương mại điện tử có dữ liệu giao dịch (trên HDFS/S3), dữ liệu người dùng (trên MySQL), và dữ liệu clickstream (trên Kafka).
*   **Giải pháp:** Sử dụng Presto để tạo báo cáo doanh thu theo thời gian thực.
*   **Cách triển khai:**
    1.  Presto kết nối với **S3** để đọc dữ liệu giao dịch lớn.
    2.  Presto kết nối với **MySQL** để lấy thông tin sản phẩm và người dùng.
    3.  Presto kết hợp cả hai nguồn để tạo báo cáo tổng hợp mà không cần sao chép dữ liệu.

### Case Study 3: Netflix (Data Visualization)
*   **Vấn đề:** Các nhóm kinh doanh cần dashboard để theo dõi lượng truy cập phim (BI Tools như Tableau, Superset).
*   **Giải pháp:** Tableau kết nối qua JDBC/ODBC vào Presto.
*   **Lợi ích:** Presto充当 "cầu nối", cho phép Tableau truy vấn dữ liệu thô trên Data Lake (S3) một cách nhanh chóng, thay vì phải import dữ liệu vào một database nhỏ hơn.

---

Dưới đây là tài liệu được phân tích và trình bày lại chi tiết theo yêu cầu của bạn, tập trung vào PrestoDB - một trong những hệ thống query engine phân tán quan trọng nhất trong kỷ nguyên Big Data.

---

# PrestoDB: Giải pháp SQL phân tán cho Big Data

## 1. Tổng quan (Overview)

**Presto** là một **distributed SQL query engine** mã nguồn mở, được phát triển và sử dụng bởi Facebook (nay là Meta) từ năm 2013. Nó được thiết kế để xử lý các truy vấn dữ liệu quy mô lớn với tốc độ cực nhanh, từ mili giây đến vài phút, khác biệt hoàn toàn so với các hệ thống batch processing truyền thống như MapReduce.

### Đặc điểm chính:
*   **Kiến trúc:** Phân tán (Distributed), Mạng lưới (Meshed).
*   **Giao tiếp:** ANSI SQL chuẩn.
*   **Mục tiêu:** Phục vụ truy vấn tương tác (Interactive Query) và phân tích dữ liệu trực tuyến (OLAP).

---

## 2. Khái niệm và Giải thích (Concepts & Explanation)

### A. Query Engine vs. Database
Presto là một **Query Engine**, không phải là một **Database**.
*   **Database:** Lưu trữ dữ liệu (Storage + Compute).
*   **Presto:** Chỉ xử lý dữ liệu (Compute). Nó kết nối và lấy dữ liệu từ các nguồn lưu trữ khác nhau (Hive, S3, MySQL, Cassandra...) và thực thi truy vấn trên đó.

### B. ANSI SQL Interface
Presto hỗ trợ chuẩn **ANSI SQL**, nghĩa là bạn có thể viết các câu truy vấn SQL quen thuộc (SELECT, JOIN, GROUP BY, Window Functions...) mà không cần học một ngôn ngữ mới như HQL (HiveQL) hay Pig Latin.

### C. Plugin Mechanism
Đây là điểm mạnh nhất của Presto. Nó có hệ thống **Plugin** cho phép kết nối tới nhiều loại data sources khác nhau.
*   **Data Sources:** Hive, HBase, Cassandra, Kafka, RDBMS (MySQL, PostgreSQL), v.v.

### D. ODBC/JDBC Connectivity
Presto cung cấp các driver **ODBC** và **JDBC** chuẩn, cho phép nó tích hợp dễ dàng với các công cụ BI (Business Intelligence) phổ biến như Tableau, PowerBI, Looker, Superset.

---

## 3. Ví dụ về Code và Truy vấn

### Ví dụ 1: Truy vấn liên跨数据源 (Cross-Source Query)
Đây là tính năng đặc biệt của Presto: kết hợp dữ liệu từ Hive và MySQL trong một câu lệnh duy nhất.

```sql
-- Giả sử ta có bảng 'user_logs' trên Hive (dữ liệu lớn)
-- và bảng 'user_info' trên MySQL (dữ liệu nhỏ, metadata)

SELECT 
    u.name, 
    COUNT(l.log_id) as total_logs
FROM 
    hive.default.user_logs l
JOIN 
    mysql.production.user_info u ON l.user_id = u.id
WHERE 
    l.date >= CURRENT_DATE - INTERVAL '7' DAY
GROUP BY 
    u.name
ORDER BY 
    total_logs DESC
LIMIT 10;
```

### Ví dụ 2: Cấu hình kết nối Hive (Pseudo-code/Config)
Mô hình hoạt động của Presto thông qua file cấu hình `catalog`.

```properties
# File: etc/catalog/hive.properties
# Định nghĩa cách Presto kết nối tới Hive Metastore

connector.name=hive-hadoop2
hive.metastore.uri=thrift://metastore-host:9083
hive.s3.aws-access-key=YOUR_ACCESS_KEY
hive.s3.aws-secret-key=YOUR_SECRET_KEY
hive.s3.endpoint=s3.amazonaws.com
```

### Ví dụ 3: Sử dụng Window Function (Phân tích dữ liệu)
Presto hỗ trợ mạnh mẽ các hàm window để phân tích dữ liệu theo thời gian hoặc nhóm.

```sql
-- Phân tích doanh số theo từng khu vực, so sánh với doanh số trung bình
SELECT 
    region,
    month,
    sales,
    AVG(sales) OVER (PARTITION BY region) as avg_region_sales
FROM 
    monthly_sales;
```

---

## 4. Hướng dẫn Sử dụng (Use Cases & How-to)

### Khi nào sử dụng Presto? (Use Cases)
1.  **Business Intelligence (BI):** Khi bạn cần kết nối Tableau/PowerBI để visualize dữ liệu lớn trên Hadoop/Data Lake nhưng cần tốc độ nhanh (sub-second response).
2.  **Data Exploration:** Khi Data Scientist cần khám phá dữ liệu tương tác (ad-hoc queries) trên petabyte dữ liệu.
3.  **ETL替代:** Thay thế các job ETL nặng nề trên MapReduce/Hive cho các tác vụ cần kết quả nhanh.
4.  **Phân tích đa nguồn:** Cần JOIN dữ liệu realtime từ Kafka/Cassandra với dữ liệu lịch sử từ Hive/S3.

### Sử dụng như thế nào? (How to use)
1.  **Cài đặt:** Cài đặt Presto Coordinator và Workers.
2.  **Cấu hình Catalog:** Tạo các file `.properties` trong thư mục `etc/catalog` để kết nối với nguồn dữ liệu (Hive, MySQL...).
3.  **Truy vấn:**
    *   **CLI:** Sử dụng command line `presto-cli`.
    *   **JDBC/ODBC:** Dùng code Java/Python hoặc kết nối trực tiếp qua BI tools.
    *   **Web UI:** Truy cập qua trình duyệt để giám sát và chạy query.

### Ưu & Nhược điểm

| Tiêu chí | Ưu điểm (Pros) | Nhược điểm (Cons) |
| :--- | :--- | :--- |
| **Tốc độ** | Rất nhanh do in-memory processing và pipelining (không lưu trung gian). | Không phù hợp cho các batch job lớn (ETL nặng) cần fault-tolerance cao. |
| **Tích hợp** | Kết nối được几乎所有 data sources thông qua Plugin. | Phải cấu hình thủ công các Catalog cho từng nguồn. |
| **SQL** | Hỗ trợ ANSI SQL chuẩn, hàm window function mạnh. | Không hỗ trợ đầy đủ các stored procedures như RDBMS truyền thống. |
| **Tài nguyên** | Chiều hướng scale out (thêm node worker) dễ dàng. | Yêu cầu tài nguyên RAM cao (thường dùng On-heap memory). |

---

## 5. Ví dụ Thực tế trong Ngành (Real-world Examples)

### Case Study: Facebook (Meta)
*   **Vấn đề:** Facebook có lượng dữ liệu khổng lồ (Petabytes) và hàng nghìn nhân viên (engineers, analysts) cần truy vấn dữ liệu hàng ngày. Hive/MapReduce quá chậm để tương tác.
*   **Giải pháp:** Xây dựng Presto.
*   **Quy mô (Thời điểm slide):**
    *   **Cluster:** 1,000 nodes (tài nguyên tính toán).
    *   **Người dùng:** > 1,000 nhân viên.
    *   **Khối lượng công việc:** 30,000+ queries/ngày.
    *   **Dữ liệu xử lý:** 1 Petabyte/ngày.
*   **Kết quả:** Cho phép các nhóm sản phẩm và phân tích thực hiện các truy vấn phức tạp trong vài giây thay vì vài giờ, thúc đẩy việc ra quyết định dựa trên dữ liệu nhanh hơn.

### Case Study: E-commerce Platform
Một công ty thương mại điện tử sử dụng Presto để:
1.  **Real-time Analytics:** Đọc dữ liệu từ Kafka (lượt click, giỏ hàng) kết hợp với dữ liệu User trên MySQL để tính toán "User Behavior Score" realtime.
2.  **Data Lake Query:** Truy vấn trực tiếp hàng tỷ file log lưu trữ trên S3 (định dạng Parquet/JSON) mà không cần load vào database.

---

## 6. Kết luận

Presto là một công cụ **cầu nối (bridge)** mạnh mẽ giữa thế giới **Big Data** (Hadoop, Data Lake) và thế giới **SQL truyền thống**. Nó cho phép các doanh nghiệp tận dụng infrastructure hiện có để thực hiện phân tích tương tác nhanh chóng, mở ra khả năng "Data Discovery" cho hàng nghìn người dùng trong tổ chức.

---

Chào bạn, tôi là chuyên gia về Big Data và Hệ thống Phân tán. Dưới đây là phân tích chi tiết về kiến trúc Presto dựa trên nội dung slide bạn cung cấp, được trình bày một cách chuyên nghiệp và chi tiết theo yêu cầu.

---

# Presto Architecture: Phân tích chi tiết

Presto là một hệ thống query engine phân tán được thiết kế để thực hiện các truy vấn SQL tốc độ cao trên dữ liệu phân tán (distributed data). Nó không phải là một database (hệ thống cơ sở dữ liệu) mà là một công cụ để query (truy vấn) dữ liệu.

## 1. Giải thích Khái niệm (Concept Explanation)

### Kiến trúc Mô-đun (Modular Architecture)
Presto có kiến trúc theo mô-đun, bao gồm các thành phần chính sau:

*   **Coordinator:** Là "bộ não" của hệ thống. Nó chịu trách nhiệm:
    *   Parse (phân tích) và compile (biên dịch) các câu lệnh SQL.
    *   Manage (quản lý) và schedule (lên lịch) các query.
    *   Monitor (giám sát) quá trình thực thi query và trả kết quả về cho client.
*   **Worker:** Là "cánh tay" thực thi. Nó chịu trách nhiệm:
    *   Execute (thực thi) các task được Coordinator giao.
    *   Process (xử lý) dữ liệu và trả kết quả về cho Coordinator.
*   **Connector:** Là "cầu nối" cho phép Presto giao tiếp với các data sources khác nhau (như Hive, MySQL, PostgreSQL, Kafka, v.v.). Presto không lưu trữ dữ liệu mà nó query trực tiếp trên các data source này.

### Mô hình Master-Slave
*   **Master (Coordinator):** Một node duy nhất quản lý toàn bộ cluster.
*   **Slave (Worker):** Các node thực thi công việc. Số lượng Worker có thể mở rộng (scale out) để tăng hiệu năng.

### Query Execution Flow (Luồng thực thi Query)
1.  Client gửi query đến **Coordinator**.
2.  Coordinator parse query và tạo ra một **Query Plan** (kế hoạch truy vấn).
3.  Query Plan được chia nhỏ thành các **Stage** (giai đoạn).
4.  Mỗi Stage được chia thành các **Task** (nhiệm vụ).
5.  Coordinator gửi Task đến các **Worker**.
6.  Worker thực thi Task, lấy dữ liệu từ **Data Source** qua **Connector**.
7.  Worker trả kết quả về Coordinator.
8.  Coordinator trả kết quả về Client.

---

## 2. Trích xuất & Cải thiện Code

Trong slide cung cấp không có đoạn code cụ thể, nhưng dựa trên kiến trúc, chúng ta có thể hình dung các đoạn code mẫu cho các thành phần chính.

### A. Code Mẫu: Tạo một Connector (Java)
Đây là pseudo-code minh họa cách một Connector có thể được định nghĩa để kết nối đến một data source tùy chỉnh.

```java
// Connector.java (Pseudo-code)
public class CustomConnector implements Connector {
    private final ConnectorMetadata metadata;
    private final ConnectorSplitManager splitManager;
    private final ConnectorRecordSetProvider recordSetProvider;

    public CustomConnector() {
        // Khởi tạo các thành phần
        this.metadata = new CustomMetadata();
        this.splitManager = new CustomSplitManager();
        this.recordSetProvider = new CustomRecordSetProvider();
    }

    @Override
    public ConnectorMetadata getMetadata() {
        return this.metadata;
    }

    @Override
    public ConnectorSplitManager getSplitManager() {
        return this.splitManager;
    }

    @Override
    public ConnectorRecordSetProvider getRecordSetProvider() {
        return this.recordSetProvider;
    }
}
```

### B. Code Mẫu: Gửi Query từ Client (Python)
Đây là ví dụ sử dụng thư viện `pyhive` để kết nối và query dữ liệu từ Presto.

```python
# client_query.py
from pyhive import presto
import pandas as pd

# Kết nối đến Presto Coordinator
cursor = presto.connect(
    host='localhost',
    port=8080,
    username='your_username',
    catalog='hive',  # Connector (ví dụ: Hive)
    schema='default'
).cursor()

# Thực thi query
query = """
SELECT 
    customer_id, 
    COUNT(*) as order_count 
FROM orders 
WHERE order_date >= '2023-01-01' 
GROUP BY customer_id 
ORDER BY order_count DESC 
LIMIT 10
"""

cursor.execute(query)

# Lấy kết quả
results = cursor.fetchall()
columns = [desc[0] for desc in cursor.description]

# Chuyển thành DataFrame để dễ xử lý
df = pd.DataFrame(results, columns=columns)
print(df)
```

### C. Code Mẫu: Worker Processing Logic (Pseudo-code)
Đây là pseudo-code mô tả logic bên trong Worker khi xử lý một Task.

```java
// WorkerTaskExecutor.java (Pseudo-code)
public class WorkerTaskExecutor {
    
    public void executeTask(TaskInfo taskInfo) {
        // 1. Nhận Task từ Coordinator
        PlanFragment fragment = taskInfo.getFragment();
        
        // 2. Tạo Operator để xử lý dữ liệu
        Operator operator = createOperator(fragment);
        
        // 3. Lấy dữ liệu từ Source (thông qua Connector)
        Page sourcePage = operator.getNextPage();
        
        // 4. Xử lý dữ liệu (Filter, Aggregation, Join)
        while (sourcePage != null) {
            Page processedPage = processPage(sourcePage, fragment);
            
            // 5. Gửi kết quả về Coordinator hoặc Worker khác (nếu có Exchange)
            sendResults(processedPage);
            
            sourcePage = operator.getNextPage();
        }
    }
}
```

---

## 3. Code Mẫu: Minh họa Kiến trúc Presto (SQL & Shell)

### Ví dụ 1: Truy vấn liên kết nhiều Data Source (Cross-Database Query)
Đây là minh họa mạnh mẽ nhất của Presto: query dữ liệu từ nhiều nguồn khác nhau trong cùng một câu lệnh SQL.

```sql
-- Presto Query: Phân tích dữ liệu từ MySQL và Hive
SELECT 
    u.country,
    SUM(o.total_amount) as revenue,
    COUNT(DISTINCT u.user_id) as active_users
FROM 
    -- Lấy dữ liệu từ MySQL qua Connector
    mysql.sales_db.users u
JOIN 
    -- Lấy dữ liệu từ Hive qua Connector
    hive.orders_db.daily_orders o 
    ON u.user_id = o.user_id
WHERE 
    o.order_date >= CURRENT_DATE - INTERVAL '7' DAY
GROUP BY 
    u.country
ORDER BY 
    revenue DESC;
```

### Ví dụ 2: Khởi động Presto Cluster (Shell Script)
Đây là các lệnh shell thường dùng để quản lý Presto.

```bash
#!/bin/bash

# Định nghĩa đường dẫn
PRESTO_HOME="/opt/presto-server"
CONFIG_DIR="$PRESTO_HOME/etc"

# Khởi động Presto Server (Coordinator hoặc Worker)
echo "Starting Presto Server..."
$PRESTO_HOME/bin/launcher start

# Kiểm tra trạng thái
echo "Checking Presto Status..."
$PRESTO_HOME/bin/launcher status

# Xem log realtime để debug
tail -f $PRESTO_HOME/var/log/server.log
```

---

## 4. Hướng dẫn Sử dụng (Usage Guide)

### Khi nào sử dụng Presto? (Use Cases)
*   **Data Lakehouse Query:** Query trực tiếp trên dữ liệu thô lưu trữ trong S3, HDFS (thông qua Hive Metastore).
*   **Phân tích nhanh (Ad-hoc Analysis):** Khi Data Analyst cần chạy các câu truy vấn nhanh để khám phá dữ liệu mà không cần ETL (Extract, Transform, Load) phức tạp.
*   **Truy vấn liên kết (Federated Query):** Cần kết hợp dữ liệu từ nhiều nguồn (ví dụ: PostgreSQL cho metadata, Hive cho dữ liệu lịch sử, Kafka cho dữ liệu real-time).
*   **Business Intelligence (BI):** Kết nối với các công cụ BI như Tableau, Superset, PowerBI để trực quan hóa dữ liệu.

### Sử dụng như thế nào? (How to use)
1.  **Cài đặt:** Tải Presto từ trang chủ, cấu hình file `config.properties` (thiết lập Coordinator/Worker) và các file `catalog` (kết nối data source).
2.  **Cấu hình Connector:** Trong thư mục `etc/catalog`, tạo file `hive.properties`, `mysql.properties` để khai báo URL và credential của data source.
3.  **Kết nối:** Sử dụng JDBC/ODBC driver hoặc CLI (Command Line Interface) để kết nối đến port 8080 của Coordinator.
4.  **Viết Query:** Viết SQL chuẩn, Presto hỗ trợ hầu hết các hàm SQL thông dụng.

### Ưu & Nhược điểm (Pros & Cons)

| Tiêu chí | Ưu điểm (Pros) | Nhược điểm (Cons) |
| :--- | :--- | :--- |
| **Tốc độ** | Query nhanh, phù hợp cho interactive queries (tương tác) nhờ kiến trúc in-memory processing. | Không tối ưu cho các batch job lớn (trên 1TB) bằng Spark. |
| **Khả năng mở rộng** | Dễ dàng scale out bằng cách thêm Worker. Coordinator không phải xử lý dữ liệu nên không bị bottleneck. | Coordinator có thể là điểm lỗi (Single Point of Failure) nếu không cấu hình HA (High Availability). |
| **Tính năng** | Hỗ trợ Federated Query (truy vấn liên kết nhiều nguồn). Không cần ETL. | Không lưu trữ dữ liệu. Phụ thuộc hoàn toàn vào performance của data source. |
| **Tiêu chuẩn** | Hỗ trợ ANSI SQL. | Một số chức năng nâng cao của Hive (như UDF tùy chỉnh) có thể không hỗ trợ ngay lập tức. |

---

## 5. Ví dụ Thực tế trong Industry (Real-world Examples)

### Case Study 1: Facebook (Người tạo ra Presto)
*   **Vấn đề:** Facebook có lượng dữ liệu khổng lồ (Petabytes) trên Hive. Họ cần một công cụ query nhanh hơn Hive (thường mất hàng phút đến hàng giờ) để phân tích dữ liệu trong thời gian thực cho các nhóm Product và Data Science.
*   **Giải pháp:** Họ xây dựng Presto. Kiến trúc Coordinator-Worker cho phép họ query dữ liệu Hive mà không cần di chuyển dữ liệu (Data Virtualization).
*   **Kết quả:** Query giảm từ hàng giờ xuống còn vài giây hoặc vài phút.

### Case Study 2: Netflix
*   **Vấn đề:** Netflix cần phân tích hành vi người dùng và log streaming từ nhiều nguồn (AWS S3, Cassandra, MySQL).
*   **Giải pháp:** Sử dụng Presto làm lớp query trung tâm. Họ dùng Presto để join dữ liệu user profile (trong MySQL) với dữ liệu xem phim (trong S3/Hive).
*   **Kết quả:** Tạo ra các báo cáo recommendation chính xác và nhanh chóng.

### Case Study 3: E-commerce Platform
*   **Kịch bản:** Một công ty thương mại điện tử muốn chạy Flash Sale.
*   **Ứng dụng Presto:**
    *   **Data Source 1 (MySQL):** Thông tin sản phẩm, giá.
    *   **Data Source 2 (Kafka/Clickstream):** Dữ liệu log click người dùng realtime.
*   **Query:** Dùng Presto để join 2 nguồn này, đếm số lượng click vào sản phẩm đang giảm giá và hiển thị dashboard realtime cho ban quản lý để điều chỉnh chiến dịch.

---

Chào bạn, tôi là chuyên gia về Big Data và Hệ thống Phân tán. Dựa trên yêu cầu của bạn, tôi sẽ phân tích và trình bày lại nội dung về **Presto** (hiện là **Trino**) một cách chuyên sâu, chi tiết và dễ hiểu.

**Lưu ý quan trọng:** Nội dung slide bạn cung cấp để trống. Tuy nhiên, dựa trên tiêu đề `4.6_presto.pdf` và kiến thức chuẩn về Presto/Trino trong các giáo trình Big Data, tôi sẽ xây dựng một bài phân tích toàn diện bao gồm các nội dung thường có trong tài liệu này (Lịch sử, Kiến trúc, Query Optimization, và các khái niệm cốt lõi).

---

# PHÂN TÍCH HỆ THỐNG TRUY VẤN PHÂN TÁN PRESTO (TRINO)

## 1. Giới thiệu và Lịch sử Phát triển (Introduction & History)

**Presto** (hiện được phát triển dưới tên **Trino**) là một hệ thống query engine mã nguồn mở, được thiết kế để thực hiện các truy vấn SQL tốc độ cao trên các nguồn dữ liệu phân tán với quy mô lớn.

### Giải thích Khái niệm
*   **Query Engine:** Không phải là một database (không lưu trữ dữ liệu), mà là một công cụ để truy vấn dữ liệu.
*   **Distributed:** Khả năng phân chia một câu truy vấn phức tạp thành nhiều phần nhỏ và thực thi song song trên nhiều máy chủ (nodes).
*   **MPP (Massively Parallel Processing):** Xử lý song song hàng loạt, giúp tốc độ truy vấn cực nhanh.

### Lịch sử
*   **2012:** Được phát triển bởi **Facebook** (nay là Meta) để giải quyết vấn đề chậm chạp của Hive và giới hạn của các hệ thống SQL-on-Hadoop cũ.
*   **2019:** Dự án được đổi tên thành **Trino** do mâu thuẫn về thương hiệu với PrestoSQL (công ty con của Presto Software Foundation). Hiện nay, **Trino** là phiên bản được khuyến nghị sử dụng.

### Khi nào sử dụng? (Use Cases)
*   Khi bạn có dữ liệu nằm ở nhiều nơi (Data Lake, Database, Data Warehouse) và cần một công cụ để query chúng từ một nơi duy nhất.
*   Khi cần tốc độ truy vấn nhanh (Interactive Analytics) thay vì xử lý batch qua đêm.
*   Phân tích dữ liệu lớm (Big Data Analytics) trên Hadoop/HDFS, S3, hoặc các kho dữ liệu đám mây.

---

## 2. Kiến trúc Hệ thống (Architecture)

Presto sử dụng kiến trúc **Master-Worker** (hoặc Coordinator-Worker).

### Các thành phần chính:
1.  **Coordinator (Máy Chủ Điều Phối):**
    *   Nhận запрос (SQL query) từ Client.
    *   Phân tích cú pháp (Parse), kiểm tra ngữ nghĩa (Validate).
    *   Tạo kế hoạch thực thi (Logical Plan -> Physical Plan).
    *   Quản lý các Worker và phân công nhiệm vụ.
2.  **Worker (Máy Thực Thi):**
    *   Nhận任务 (Task) từ Coordinator.
    *   Trực tiếp đọc dữ liệu từ các Connectors.
    *   Xử lý dữ liệu và trả kết quả về Coordinator.

### Connector (Bộ kết nối)
Presto không lưu trữ dữ liệu. Nó kết nối qua **Connector** để truy vấn dữ liệu từ các hệ thống khác như:
*   Hive (HDFS, S3)
*   MySQL, PostgreSQL
*   Kafka, Elasticsearch, Cassandra...

### Mô hình Query Processing
Khi một câu truy vấn được gửi đi:
1.  **SQL** được gửi đến Coordinator.
2.  Coordinator tạo **Stage** (Giai đoạn) và **Task**.
3.  Task được gửi đến Worker.
4.  Worker đọc dữ liệu từ Source, xử lý (Filter, Aggregate) và trả về.

---

## 3. Trích xuất và Cải thiện Code (Code Extraction & Improvement)

Trong Presto/Trino, "code" thường là các câu lệnh SQL mở rộng hoặc các script cấu hình. Dưới đây là các ví dụ được viết lại chuẩn xác.

### A. Cấu hình Connector (Ví dụ: Hive)
Đây là file cấu hình để Presto kết nối với Hive Metastore.

```properties
# File: etc/catalog/hive.properties
connector.name=hive-hadoop2
hive.metastore.uri=thrift://hive-metastore:9083
hive.non-managed-table-writes-enabled=true
hive.s3.aws-access-key=YOUR_ACCESS_KEY
hive.s3.aws-secret-key=YOUR_SECRET_KEY
```

### B. Cấu trúc Query với Window Functions
Presto hỗ trợ mạnh mẽ Window Functions để phân tích dữ liệu theo nhóm mà không cần JOIN nhiều lần.

```sql
-- SQL: Phân tích doanh thu theo từng khu vực (Window Function)
SELECT 
    nation_name,
    region_name,
    sum_revenue,
    -- Tính tỷ trọng doanh thu trong khu vực
    SUM(sum_revenue) OVER (PARTITION BY region_name) as total_region_revenue,
    -- Xếp hạng quốc gia trong khu vực
    RANK() OVER (PARTITION BY region_name ORDER BY sum_revenue DESC) as rank_in_region
FROM (
    SELECT 
        n.name as nation_name,
        r.name as region_name,
        SUM(o.totalprice) as sum_revenue
    FROM orders o
    JOIN customer c ON o.custkey = c.custkey
    JOIN nation n ON c.nationkey = n.nationkey
    JOIN region r ON n.regionkey = r.regionkey
    WHERE year(o.orderdate) = 2023
    GROUP BY n.name, r.name
);
```

### C. Script Shell để chạy Query (CLI)
```bash
#!/bin/bash
# Script để chạy một truy vấn Presto và lưu kết quả ra file
PRESTO_SERVER="localhost:8080"
CATALOG="hive"
SCHEMA="default"

# Truy vấn lấy danh sách top 10 user có giao dịch nhiều nhất
QUERY="SELECT custkey, count(*) as total_orders FROM $CATALOG.$SCHEMA.orders GROUP BY custkey ORDER BY total_orders DESC LIMIT 10"

# Chạy query bằng Presto CLI
docker exec -it presto-cli \
  presto --server $PRESTO_SERVER \
  --catalog $CATALOG \
  --schema $SCHEMA \
  --execute "$QUERY" > /tmp/top_users.csv

echo "Query completed. Result saved to /tmp/top_users.csv"
```

---

## 4. Query Optimization (Tối ưu hóa truy vấn)

Đây là phần quan trọng nhất trong Presto. Slide thường đề cập đến các kỹ thuật sau:

### A. Predicate Pushdown (Đẩy điều kiện xuống dưới)
*   **Giải thích:** Presto sẽ cố gắng "đẩy" các điều kiện `WHERE` xuống càng gần nguồn dữ liệu càng tốt. Thay vì tải toàn bộ dữ liệu lên Presto rồi mới lọc, Presto sẽ yêu cầu Hive/MySQL lọc dữ liệu trước.
*   **Ví dụ:** `WHERE date = '2023-01-01'` sẽ được chuyển xuống Hive để chỉ đọc phân vùng (partition) đó.

### B. Dynamic Filtering (Lọc động)
*   **Giải thích:** Khi JOIN giữa bảng lớn (Fact) và bảng nhỏ (Dimension), Presto sẽ lấy dữ liệu từ bảng nhỏ trước, tạo ra một danh sách các giá trị (Filter), và gửi danh sách này đến các Worker đang đọc bảng lớn để loại bỏ dữ liệu thừa ngay lập tức.

### C. Cost-Based Optimizer (CBO)
*   **Giải thích:** Dựa trên thống kê (Statistics) của dữ liệu (số dòng, độ phân tán), Presto sẽ chọn cách JOIN tốt nhất (ví dụ: Broadcast Join vs Hash Join).

---

## 5. Hướng dẫn Sử dụng (How to use)

### Sử dụng như thế nào?
1.  **Cài đặt:** Tải binary từ trino.io hoặc dùng Docker.
2.  **Cấu hình (Configuration):**
    *   `config.properties`: Cấu hình Coordinator/Worker.
    *   `catalog/*.properties`: Cấu hình kết nối nguồn dữ liệu.
3.  **Truy vấn:**
    *   **CLI:** Dùng command line `presto`.
    *   **JDBC/ODBC:** Tích hợp vào các BI tools (Tableau, PowerBI) hoặc Java/Python application.
    *   **Web UI:** Truy cập `http://<coordinator>:8080` để theo dõi query.

### Ưu & Nhược điểm

| Tiêu chí | Ưu điểm (Pros) | Nhược điểm (Cons) |
| :--- | :--- | :--- |
| **Tốc độ** | Rất nhanh (Interactive), xử lý song song mạnh mẽ. | Không tối ưu cho các job chạy qua đêm (Batch) bằng Spark. |
| **Tính linh hoạt** | Truy vấn nhiều nguồn dữ liệu cùng lúc (Data Federation). | Không lưu trữ dữ liệu, phụ thuộc vào nguồn dữ liệu gốc. |
| **Cộng đồng** | Mã nguồn mở mạnh mẽ, được hỗ trợ bởi các ông lớn (AWS, Google, Meta). | Cần kỹ thuật viên có kinh nghiệm để tối ưu hóa (Tuning). |
| **Bộ nhớ** | Xử lý dữ liệu lớn tốt (Out-of-core processing). | Có thể gây quá tải Coordinator nếu query quá phức tạp. |

---

## 6. Ví dụ Thực tế trong Industry (Real-world Examples)

### Case Study 1: Streaming Data (Netflix)
Netflix sử dụng Presto/Trino để phân tích dữ liệu streaming thời gian thực.
*   **Bài toán:** Họ cần đếm số lượng người dùng xem phim theo từng giây, từng quốc gia.
*   **Giải pháp:** Dùng Presto query trực tiếp lên dữ liệu thô (Raw Data) lưu trên S3 (Data Lake) mà không cần load vào Database. Điều này giúp họ thay đổi cấu trúc dữ liệu (Schema) linh hoạt.

### Case Study 2: Business Intelligence (Airbnb)
Airbnb sử dụng Presto làm nền tảng cho các truy vấn tự phục vụ (Self-service BI).
*   **Bài toán:** Hàng nghìn nhân viên (kỹ sư, product manager) cần chạy SQL để lấy dữ liệu báo cáo hàng ngày.
*   **Giải pháp:** Họ xây dựng một lớp trung gian (Presto Gateway) để phân bổ truy vấn. Presto giúp họ query dữ liệu từ Hive và MySQL đồng thời, kết hợp lại để tạo báo cáo doanh thu.

### Case Study 3: Ngân hàng (Fintech)
*   **Bài toán:** Kiểm tra gian lận giao dịch.
*   **Giải pháp:** Sử dụng Presto với **Dynamic Filtering**. Khi một giao dịch bất thường được phát hiện ở hệ thống Kafka, Presto sẽ tự động JOIN với dữ liệu lịch sử khách hàng (lưu trong HDFS) để đánh giá rủi ro trong thời gian thực.

---

## Tóm tắt (Summary)

Presto (Trino) là một công cụ không thể thiếu trong kiến trúc Big Data hiện đại. Nó đóng vai trò là "bộ não" để hỏi và phân tích dữ liệu mà không cần di chuyển dữ liệu (Data Virtualization). Với khả năng mở rộng, hỗ trợ SQL chuẩn và tối ưu query thông minh, Presto là lựa chọn số 1 cho các hệ thống phân tích dữ liệu quy mô lớn.

---

Chào bạn, tôi là chuyên gia về Big Data và Hệ thống Phân tán. Dưới đây là phân tích chi tiết về nội dung slide Presto của bạn, được trình bày một cách chuyên nghiệp và dễ hiểu theo các yêu cầu bạn đưa ra.

---

# Phân tích Presto: Connectors và Kiến trúc Phân tán

Presto (hiện được gọi là Trino) là một công cụ truy vấn SQL phân tán hiệu suất cao được thiết kế để xử lý dữ liệu quy mô lớn từ nhiều nguồn dữ liệu khác nhau. Slide này tập trung vào hai khái niệm cốt lõi: **Connectors** và **Kiến trúc Phân tán**.

## 1. Presto Connectors

### Giải thích Khái niệm (Concept Explanation)
**Connectors (Bộ kết nối)** là các plugin cho phép Presto giao tiếp và truy cập dữ liệu từ các hệ thống lưu trữ khác nhau. Chúng đóng vai trò như một cây cầu, giúp Presto có thể "nói chuyện" với các nguồn dữ liệu như Hive, Cassandra, hay MySQL mà không cần di chuyển dữ liệu.

Mỗi Connector được viết bằng **Java** và chịu trách nhiệm thực hiện các nhiệm vụ sau:
1.  **Truy cập Storage and Metadata**: Đọc dữ liệu thực tế từ hệ thống lưu trữ (như HDFS, S3) và lấy thông tin metadata (như cấu trúc bảng, cột).
2.  **Cung cấp Schema cho Coordinator**: Nói với Coordinator (trình điều phối) về cấu trúc của các bảng (table schema).
3.  **Cung cấp Rows cho Workers**: Cung cấp dữ liệu thực tế (các hàng dữ liệu) cho các Worker khi có truy vấn.

### Các Implementations (Lựa chọn phổ biến)
*   **Hive Connector**: Kết nối với Hive Metastore và đọc dữ liệu từ HDFS/S3. Đây là connector phổ biến nhất.
*   **Cassandra Connector**: Truy vấn trực tiếp dữ liệu từ Apache Cassandra.
*   **JDBC Connector**: Cho phép kết nối tới bất kỳ cơ sở dữ liệu nào hỗ trợ JDBC (như MySQL, PostgreSQL). *Lưu ý: Slide ghi là prerelease, nhưng hiện tại đã rất成熟 (trưởng thành).*

### Hướng dẫn Sử dụng & Ví dụ

#### Khi nào sử dụng?
*   Khi bạn có dữ liệu nằm rải rác ở nhiều nơi (Data Lake, NoSQL, RDBMS) và muốn truy vấn chúng bằng một câu lệnh SQL duy nhất.
*   Khi bạn muốn phân tích dữ liệu trong Hive nhưng ngại cấu hình phức tạp của Hive hoặc muốn tốc độ nhanh hơn.

#### Sử dụng như thế nào?
Bạn định nghĩa một Connector bằng cách cấu hình file `etc/catalog/<tên_catalog>.properties` trên server Presto.

**Ví dụ Cấu hình Connector cho Hive:**
```properties
# File: etc/catalog/hive.properties
connector.name=hive-hadoop2
hive.metastore.uri=thrift://hive-metastore:9083
hive.non-managed-table-writes-enabled=true
```

**Ví dụ Cấu hình Connector cho MySQL qua JDBC:**
```properties
# File: etc/catalog/mysql.properties
connector.name=mysql
connection-url=jdbc:mysql://mysql-host:3306/database_name
connection-user=root
connection-password=secret
```

#### Ưu & Nhược điểm
| Ưu điểm | Nhược điểm |
| :--- | :--- |
| **Đa năng**: Truy vấn dữ liệu từ nhiều nguồn trong một câu lệnh SQL (Federated Query). | **Phụ thuộc vào Metadata**: Phụ thuộc nhiều vào Hive Metastore hoặc cấu trúc nguồn dữ liệu. |
| **Không cần di chuyển dữ liệu**: Phân tích dữ liệu tại chỗ (Data Virtualization). | **Độ phức tạp của Connector**: Viết một custom connector đòi hỏi hiểu biết sâu về Java và API của nguồn dữ liệu. |

#### Ví dụ Thực tế trong Ngành
Một công ty E-commerce có dữ liệu giao dịch trong **MySQL**, dữ liệu hành vi người dùng (log) trong **Hive/HDFS**, và dữ liệu giỏ hàng tạm trong **Cassandra**. Họ sử dụng Presto với các Connector tương ứng để tạo một báo cáo tổng hợp:
*   Lấy tổng doanh thu từ MySQL.
*   Lấy số lần click từ Hive.
*   Lấy thông tin giỏ hàng từ Cassandra.
*   Kết hợp lại bằng một câu query Presto duy nhất.

---

## 2. Kiến trúc Phân tán (Distributed Architecture)

### Giải thích Khái niệm (Concept Explanation)
Presto hoạt động theo mô hình **Client-Server** và có thể mở rộng quy mô (scale out) bằng cách thêm các node worker. Kiến trúc này bao gồm 3 loại server chính:

1.  **Coordinator**:
    *   Là "bộ não" của hệ thống.
    *   Chịu trách nhiệm phân tích cú pháp (parse), lập kế hoạch (plan) và quản lý việc thực thi truy vấn.
    *   Giao tiếp với Client để nhận SQL và trả kết quả.
    *   Chỉ có 1 Coordinator duy nhất trong một cluster.

2.  **Worker**:
    *   Là "cánh tay" thực thi.
    *   Chịu trách nhiệm thực thi các task do Coordinator giao, lấy dữ liệu từ Connector và xử lý các phép toán (aggregation, join).
    *   Có thể có nhiều Worker để tăng tốc độ xử lý.

3.  **Discovery Service**:
    *   Dịch vụ khám phá, thường được đóng gói bên trong Coordinator.
    *   Giúp các Worker đăng ký với Coordinator và đảm bảo Coordinator biết trạng thái của các Worker (alive or dead).

**Lưu ý quan trọng:** Presto là **NOT a database**. Nó không lưu trữ dữ liệu (không có storage engine). Nó chỉ là một công cụ query engine, cung cấp SQL để truy vấn các kho dữ liệu đã tồn tại.

### Giao thức và Tích hợp
*   **Client Protocol**: Sử dụng **HTTP + JSON**. Điều này giúp Presto dễ dàng tích hợp với bất kỳ ngôn ngữ lập trình nào có thể gửi HTTP request.
*   **Language Bindings**: Các thư viện client đã có sẵn cho Ruby, Python, PHP, Java (JDBC), R, Node.JS...

### Hướng dẫn Sử dụng & Ví dụ

#### Khi nào sử dụng?
*   Cần truy vấn nhanh (ad-hoc queries) trên lượng dữ liệu lớn (Petabyte) mà không cần chờ batch job (như MapReduce).
*   Cần một giải pháp SQL linh hoạt để thay thế cho việc phải học các API phức tạp của Hadoop/Spark.

#### Sử dụng như thế nào?
Người dùng tương tác với Presto thông qua **Presto CLI** (Command Line Interface) hoặc các driver JDBC/ODBC.

**Ví dụ Shell Script (Presto CLI):**
Để chạy một truy vấn từ dòng lệnh, bạn có thể dùng lệnh sau:

```bash
# Truy vấn dữ liệu từ Hive catalog (database hive) và schema default
presto --server localhost:8080 \
       --catalog hive \
       --schema default \
       --execute "SELECT count(*) FROM my_large_table;"
```

**Ví dụ Code Python (Sử dụng thư viện `pyhive`):**
```python
from pyhive import presto

# Kết nối đến Coordinator
cursor = presto.connect(
    host='localhost',
    port=8080,
    username='your_user',
    catalog='hive',
    schema='default'
).cursor()

# Thực thi câu lệnh SQL
cursor.execute("SELECT name, age FROM users WHERE age > 25")

# Lấy kết quả
results = cursor.fetchall()
for row in results:
    print(f"Name: {row[0]}, Age: {row[1]}")
```

#### Ưu & Nhược điểm
| Ưu điểm | Nhược điểm |
| :--- | :--- |
| **High Performance**: Xử lý song song trên nhiều Worker, tối ưu hóa bộ nhớ (memory-bound). | **Không lưu trữ dữ liệu**: Nếu nguồn dữ liệu (như Hive) chậm, Presto cũng sẽ chậm theo. |
| **Mở rộng dễ dàng**: Dễ dàng thêm Worker để tăng công suất. | **Yêu cầu tài nguyên RAM**: Các Worker cần nhiều RAM để xử lý các task trong bộ nhớ. |
| **Tiêu chuẩn SQL**: Hỗ trợ SQL ANSI chuẩn. | |

#### Ví dụ Thực tế trong Ngành
Một Data Scientist cần phân tích dữ liệu log thời gian thực để tìm lỗi hệ thống.
1.  **Architecture**: Cluster Presto gồm 1 Coordinator và 50 Worker.
2.  **Process**: Data Scientist kết nối qua JDBC từ tool Jupyter Notebook.
3.  **Execution**: Câu query phức tạp được gửi đến Coordinator -> Coordinator chia nhỏ task -> Gửi xuống các Worker -> Worker đọc dữ liệu log từ Kafka/HDFS qua Connector -> Xử lý và trả kết quả về cho Notebook trong vài giây thay vì vài phút như Hive.

---

## Tóm tắt Phân tích

Nội dung slide này giới thiệu Presto như một kiến trúc **Microservices** cho việc truy vấn dữ liệu:
*   **Connectors** là các module linh hoạt để kết nối dữ liệu.
*   **Architecture** là mô hình Coordinator/Worker chuẩn để đảm bảo hiệu năng và độ tin cậy.
*   **Philosophy**: Presto không lưu trữ dữ liệu, nó chỉ là "người dịch" SQL cho các hệ thống dữ liệu hiện có.

---

Dưới đây là tài liệu phân tích chi tiết về mô hình thực thi của Presto dựa trên nội dung slide bạn cung cấp, được trình bày chuyên nghiệp bằng tiếng Việt.

---

# Presto Execution Model: Phân tích và Hướng dẫn Chi tiết

## 1. Tổng quan về Mô hình Thực thi (Execution Model)

Presto được thiết kế như một công cụ query engine (bộ truy vấn) phân tán hiệu năng cao. Điểm khác biệt lớn nhất so với các hệ thống cũ (như Hadoop MapReduce) là Presto không thực thi các tác vụ trên đĩa (disk-bound) mà tập trung vào xử lý dữ liệu trong bộ nhớ (in-memory processing) và tối ưu hóa luồng thực thi.

### Presto là gì và KHÔNG phải là gì?
*   **KHÔNG phải là MapReduce:** Presto không sử dụng mô hình MapReduce của Hadoop. Nó không lưu trung gian dữ liệu xuống đĩa cứng sau mỗi bước xử lý (intermediate disk I/O), giúp giảm độ trễ đáng kể.
*   **Cấu trúc tương tự:** Mô hình của Presto tương đồng với **Apache Tez** (cùng thuộc hệ sinh thái Hadoop nhưng tối ưu hơn MapReduce) hoặc các cơ sở dữ liệu **MPP (Massively Parallel Processing)** truyền thống như Teradata hay Greenplum.

### Cấu trúc Kiến trúc Tổng thể
Hệ thống Presto hoạt động theo mô hình Client-Server, bao gồm hai thành phần chính:
1.  **Coordinator:** Bộ não của hệ thống, chịu trách nhiệm phân tích, lập kế hoạch và quản lý luồng thực thi.
2.  **Worker:** Các cỗ máy thực thi, chịu trách nhiệm tải và xử lý dữ liệu.

---

## 2. Quy trình Thực thi Truy vấn (How Query Runs?)

Khi một truy vấn SQL được gửi đến Presto, nó sẽ đi qua một quy trình khép kín dưới sự điều phối của **Coordinator**.

### Các bước chi tiết:

1.  **SQL Parser (Trình phân tích cú pháp):**
    *   Chuyển đổi câu lệnh SQL thô thành một cấu trúc cây (Abstract Syntax Tree - AST).
    *   Kiểm tra cú pháp và xác thực quyền truy cập.

2.  **Query Planner (Bộ lập kế hoạch truy vấn):**
    *   Biến cây cú pháp thành một kế hoạch thực thi logic (Logical Plan).
    *   Thực hiện các tối ưu hóa (Optimization) như谓下推 (predicate pushdown), loại bỏ các cột không cần thiết, hoặc gộp các phép toán.

3.  **Execution Planner (Bộ lập kế hoạch thực thi):**
    *   Chuyển đổi kế hoạch logic thành kế hoạch vật lý (Physical Plan).
    *   Phân chia kế hoạch thành các **Stage** (Giai đoạn) và **Task** (Nhiệm vụ) để phân phối cho các Worker.
    *   Tạo ra các **DAG (Directed Acyclic Graph)** để quản lý phụ thuộc giữa các tác vụ.

4.  **Task Execution Scheduler (Bộ lập lịch thực thi tác vụ):**
    *   Gửi các Task đến các Worker.
    *   Theo dõi trạng thái, xử lý lỗi và kết quả trả về.

---

## 3. Phân tích Chi tiết các Thành phần

### A. Coordinator
Coordinator là node điều phối trung tâm. Nó không xử lý dữ liệu thực tế mà chỉ xử lý metadata và kế hoạch.
*   **Trách nhiệm:**
    *   Nhận yêu cầu từ client (JDBC/ODBC).
    *   Duy trì phiên bản metadata của các bảng (thông qua Hive Metastore hay các connector khác).
    *   Quản lý vòng đời của query.

### B. Query Planner
Đây là nơi diễn ra quá trình tối ưu hóa quan trọng nhất.
*   **Cơ chế:** Dựa trên nguyên tắc **Rule-based** hoặc **Cost-based optimization (CBO)** (tùy phiên bản).
*   **Output:** Tạo ra một DAG của các Stage.

---

## 4. Code Mẫu và Minh họa

Do Presto là một hệ thống phức tạp, code "trong lõi" (Java) rất khó trình bày ngắn gọn. Dưới đây là các minh họa về cách Presto hoạt động và cách sử dụng nó.

### Ví dụ 1: Quy trình Query Plan (Pseudo-code)

Đây là minh họa cho quá trình Coordinator tạo ra Execution Plan.

```python
# Pseudo-code minh họa quy trình Planner

class QueryCoordinator:
    def receive_sql(self, sql_query):
        # 1. SQL Parser
        ast = self.sql_parser.parse(sql_query)
        
        # 2. Query Planner (Logical Plan)
        # Tối ưu hóa: Chọn thuật toán Join (Hash Join, Merge Join)
        logical_plan = self.query_planner.optimize(ast)
        
        # 3. Execution Planner (Physical Plan)
        # Phân chia thành các Stage (ví dụ: Stage 1: Scan, Stage 2: Aggregate)
        execution_plan = self.execution_planner.create_dag(logical_plan)
        
        # 4. Task Scheduler
        # Phân phối Task đến các Worker
        for stage in execution_plan.stages:
            for task in stage.tasks:
                worker = self.get_available_worker()
                worker.assign_task(task)
```

### Ví dụ 2: Sử dụng Presto CLI (Thực tế)

Đây là cách một kỹ sư dữ liệu tương tác với Presto.

```bash
# Kết nối vào Coordinator của Presto
presto --server localhost:8080 --catalog hive --schema default

# Thực thi một truy vấn phức tạp
# Presto sẽ tự động lập kế hoạch và phân phối
SELECT 
    nation, 
    count(*) as total_orders 
FROM orders 
JOIN customer ON orders.custkey = customer.custkey 
WHERE year = 2023 
GROUP BY nation;
```

### Ví dụ 3: Truy vấn thông qua JDBC (Java)

```java
import java.sql.*;

public class PrestoExample {
    public static void main(String[] args) throws Exception {
        // Cấu hình kết nối JDBC
        String url = "jdbc:presto://localhost:8080/hive/default";
        String user = "admin";
        
        try (Connection connection = DriverManager.getConnection(url, user, null);
             Statement statement = connection.createStatement();
             ResultSet rs = statement.executeQuery("SELECT * FROM sales_data LIMIT 10")) {
            
            while (rs.next()) {
                System.out.println(rs.getString("product_name"));
            }
        }
    }
}
```

---

## 5. Hướng dẫn Sử dụng & Phân tích Ưu/Nhược điểm

### Khi nào sử dụng Presto? (Use Cases)
*   **Data Lake Querying:** Truy vấn trực tiếp trên dữ liệu thô lưu trữ trong S3, HDFS (Hive, Iceberg, Delta Lake).
*   **OLAP Phân tích:** Các báo cáo định kỳ, phân tích đa chiều (Ad-hoc queries).
*   **Federated Query:** Truy vấn liên kết nhiều nguồn dữ liệu khác nhau (ví dụ: Join dữ liệu từ MySQL + Hive + Kafka).

### Sử dụng như thế nào? (How to use)
1.  **Cài đặt:** Cài đặt Coordinator và Worker (hoặc dùng Presto SQL, Starburst, Trino).
2.  **Cấu hình Catalog:** Định nghĩa nguồn dữ liệu (Connector) như Hive, MySQL, Kafka.
3.  **Kết nối:** Sử dụng Client CLI hoặc JDBC/ODBC driver.
4.  **Viết SQL:** Viết SQL chuẩn, Presto sẽ tự động xử lý phần lập kế hoạch.

### Ưu & Nhược điểm

| Tiêu chí | Ưu điểm (Pros) | Nhược điểm (Cons) |
| :--- | :--- | :--- |
| **Hiệu năng** | Rất nhanh do xử lý in-memory và pipelining (không chờ I/O). | Hiệu năng giảm nếu dữ liệu quá lớn không fit trong RAM của Worker. |
| **Kiến trúc** | MPP Architecture: Tăng tài nguyên (Worker) dễ dàng để scale out. | Coordinator có thể trở thành điểm nghẽn (bottleneck) nếu số lượng query đồng thời quá lớn. |
| **Tương thích** | Hỗ trợ SQL ANSI, kết nối được với nhiều nguồn dữ liệu (Federated). | Không hỗ trợ ghi (Write) dữ liệu trực tiếp (chỉ Read và Transform). |
| **Quản lý** | Đơn giản hơn Hadoop MapReduce. | Cần quản lý tài nguyên (Memory/CPU) chặt chẽ để tránh crash Worker. |

---

## 6. Ví dụ Thực tế trong Công nghiệp

### Case Study: Phân tích hành vi người dùng (E-commerce)
*   **Bài toán:** Một công ty TMNT có hàng TB dữ liệu log người dùng lưu trên Amazon S3 (dạng file Parquet). Họ cần phân tích xem người dùng ở khu vực nào có tỷ lệ mua hàng cao nhất trong 1 giờ qua.
*   **Cách Presto giải quyết:**
    1.  **Source:** Dữ liệu S3 được khai báo qua Hive Metastore (Catalog `s3_logs`).
    2.  **Execution:** Kỹ sư viết truy vấn SQL.
    3.  **Planner:** Presto tạo DAG, các Worker sẽ đọc song song các file Parquet từ S3.
    4.  **Result:** Thay vì phải chạy MapReduce mất 15-20 phút, Presto trả kết quả trong **vài giây đến vài phút** nhờ việc tối ưu hóa DAG và xử lý song song dữ liệu ngay tại bộ nhớ.

### Case Study: Data Federation (Điện lực)
*   **Bài toán:** Kết hợp dữ liệu khách hàng từ hệ thống CRM (Oracle) và dữ liệu tiêu thụ điện năng từ Hive.
*   **Cách Presto giải quyết:** Sử dụng 2 Catalog (`oracle_crm` và `hive_meter`). Presto sẽ pull data từ cả 2 source, thực hiện Join ngay tại memory của Worker mà không cần ETL (Extract-Transform-Load) dữ liệu về một nơi trước đó.

---

Chào bạn, với vai trò là một chuyên gia về Big Data và Hệ thống Phân tán, tôi sẽ phân tích và trình bày lại nội dung từ tài liệu slide về Presto (một engine query phân tán nổi tiếng) một cách chi tiết và chuyên nghiệp dưới đây.

---

# Phân Tích Hệ thống Phân Tán: Kiến Trúc và Lập Lịch Truy Vấn trong Presto

Tài liệu này t tổng hợp các khái niệm cốt lõi về cách Presto xử lý các truy vấn phức tạp thông qua mô hình **Master-Worker**. Dưới đây là phân tích chi tiết.

## 1. Các Giai Đoạn Xử Lý (Stages)

Trong kiến trúc của Presto, một truy vấn (query) thường quá phức tạp để xử lý trên một máy duy nhất. Do đó, nó được chia nhỏ thành các đơn vị xử lý song song được gọi là **Stages**.

### Giải thích khái niệm
Một **Stage** là một phần của kế hoạch thực thi truy vấn (query execution plan) có thể được thực thi song song trên nhiều worker node. Mỗi worker sẽ thực hiện cùng một phép tính (computation) nhưng trên các tập dữ liệu đầu vào (input data) khác nhau.

Để các Stage này có thể trao đổi dữ liệu với nhau, Presto sử dụng cơ chế **Shuffle** (trao đổi dữ liệu). Dữ liệu được buffer (tạm trữ) trong bộ nhớ (in-memory) và chuyển từ Stage này sang Stage khác.

### Ưu & Nhược điểm
*   **Ưu điểm:**
    *   **Tốc độ:** Xử lý song song giúp tận dụng tối đa tài nguyên cluster.
    *   **Tính linh hoạt:** Phân chia công việc dựa trên kế hoạch truy vấn (logical plan).
*   **Nhược điểm:**
    *   **Latency do Shuffle:** Việc trao đổi dữ liệu giữa các Stage (Shuffles) làm tăng độ trễ (latency).
    *   **Tiêu tốn tài nguyên:** Sử dụng nhiều bộ nhớ đệm (buffer memory) và tốn CPU overhead để nén/giải nén và truyền dữ liệu.

### Ví dụ thực tế
Giả sử bạn có một truy vấn SQL phức tạp: `SELECT region, SUM(sales) FROM orders JOIN customers ON orders.cust_id = customers.id GROUP BY region`.

Presto sẽ chia thành các Stage:
1.  **Stage 1 (Scan & Filter):** Đọc dữ liệu từ `orders` và `customers` (có thể song song ở nhiều node).
2.  **Stage 2 (Exchange/Shuffle):** Chuyển dữ liệu để chuẩn bị cho Join (dựa trên `cust_id`).
3.  **Stage 3 (Join):** Nối hai bảng lại.
4.  **Stage 4 (Aggregation):** Tính toán `SUM` và `GROUP BY`.

---

## 2. Các Nhiệm Vụ (Tasks)

Nếu Stage là một "đơn vị logic" của kế hoạch, thì **Task** là đơn vị vật lý thực sự được thực thi trên worker.

### Giải thích khái niệm
*   **Coordinator (Điều phối viên):** Nhận kế hoạch từ Stage và phân phối xuống các Worker dưới dạng các **Tasks**.
*   **Quy tắc:** 1 Task / 1 Worker / 1 Stage.
*   **Cấu trúc:** Một Task có thể chứa nhiều **Pipelines**. Pipeline là một chuỗi các **Operators** (toán tử).

### Minh họa cấu trúc
```text
Stage (Logical Unit)
└── Task (Physical Execution Unit on Worker)
    ├── Pipeline 1
    │   ├── Operator: TableScan
    │   ├── Operator: Filter
    │   └── Operator: Project
    └── Pipeline 2
        ├── Operator: HashAggregation
        └── Operator: Output
```

### Ví dụ Code Mẫu (Giả lập cấu trúc Task/Pipeline)
Trong Presto, người dùng không trực tiếp tạo Task, nhưng dưới đây là mô phỏng logic của một Pipeline xử lý dữ liệu:

```python
class Operator:
    def process(self, data):
        # Logic xử lý dữ liệu
        pass

class TableScanOperator(Operator):
    def process(self, data):
        return f"Scanned {data}"

class FilterOperator(Operator):
    def process(self, data):
        if "valid" in data:
            return data
        return None

# Một Pipeline liên kết các Operators
class Pipeline:
    def __init__(self):
        self.operators = []
    
    def add_operator(self, op):
        self.operators.append(op)
    
    def execute(self, input_data):
        current_data = input_data
        for op in self.operators:
            current_data = op.process(current_data)
        return current_data

# Giả lập một Task
def worker_task_execution():
    pipeline = Pipeline()
    pipeline.add_operator(TableScanOperator())
    pipeline.add_operator(FilterOperator())
    
    # Worker xử lý dữ liệu đầu vào
    result = pipeline.execute("raw_data_valid")
    print(f"Task Output: {result}")

worker_task_execution()
```

---

## 3. Lập Lịch Truy Vấn (Scheduling)

Để tối ưu hóa việc thực thi, Presto sử dụng **Scheduler** để đưa ra các quyết định về việc khi nào và ở đâu các Stage được thực thi. Có hai chính sách lập lịch chính.

### A. Stage Scheduling: All-at-once (Song song hoàn toàn)

#### Giải thích
Khi bắt đầu truy vấn, Scheduler sẽ lên lịch cho **tất cả các Stage** của kế hoạch thực thi đồng thời (concurrently). Dữ liệu được xử lý ngay khi nó có sẵn.

#### Khi nào sử dụng?
*   **Interactive Analytics (Phân tích tương tác):** Khi người dùng cần phản hồi nhanh.
*   **Developer/Advertiser Analytics:** Phân tích nhanh để ra quyết định.
*   **A/B Testing:** Kiểm tra các biến thể cần kết quả tức thì.

#### Ưu điểm
*   Giảm thời gian chờ (wall clock time).
*   Giảm độ trễ (latency).

### B. Stage Scheduling: Phased (Theo giai đoạn)

#### Giải thích
Scheduler chỉ lên lịch cho một Stage cụ thể khi Stage đó sẵn sàng hoặc theo chính sách nhất định. Nó sẽ gán các Tasks cho worker nodes từng giai đoạn một.

#### Khi nào sử dụng?
*   **Batch Analytics (Phân tích hàng loạt):** Các truy vấn phức tạp, xử lý lượng dữ liệu lớn, không yêu cầu phản hồi ngay lập tức.

#### Ưu điểm
*   **Tối ưu bộ nhớ (Memory efficiency):** Giảm tải cho bộ nhớ bằng cách không thực thi tất cả cùng một lúc, tránh tràn bộ nhớ khi dữ liệu quá lớn.

### Bảng so sánh

| Chính sách | Cơ chế hoạt động | Use Case điển hình | Ưu điểm chính |
| :--- | :--- | :--- | :--- |
| **All-at-once** | Khởi chạy tất cả các Stage ngay khi có thể. | Interactive, A/B Testing | Tối ưu Latency. |
| **Phased** | Chờ Stage trước hoàn thành hoặc dữ liệu sẵn sàng mới kích hoạt Stage tiếp theo. | Batch Processing | Tối ưu Memory. |

---

## 4. Tóm tắt & Kết luận

Hệ thống Presto hoạt động dựa trên sự phối hợp nhịp nhàng giữa các khái niệm:
1.  **Stages** chia nhỏ công việc logic.
2.  **Tasks** thực thi vật lý trên các Worker thông qua **Pipelines** và **Operators**.
3.  **Scheduler** linh hoạt lựa chọn giữa **All-at-once** (cho nhanh) và **Phased** (cho khỏe/ổn định) tùy theo nhu cầu của bài toán (Interactive vs Batch).

Việc hiểu rõ cơ chế **Shuffle** và **Scheduling** này là chìa khóa để tối ưu hóa các truy vấn Big Data trong môi trường thực tế.

---

Chào bạn, tôi là một chuyên gia về Big Data và Hệ thống Phân tán. Dưới đây là phân tích chi tiết về nội dung slide Presto của bạn, được trình bày một cách chuyên nghiệp bằng tiếng Việt với các ví dụ minh họa thực tế.

---

# Phân tích Hệ thống Presto: Lập kế hoạch, Tối ưu hóa và Sắp xếp

Tài liệu này tập trung vào ba trụ cột chính của Presto (trước đây là Trino) trong việc xử lý các truy vấn Big Data: **Lập kế hoạch thực thi (Task Scheduling)**, **Quản lý dữ liệu đầu vào (Split Scheduling)**, và **Tối ưu hóa truy vấn (Query Optimization)**.

## 1. Lập kế hoạch Thực thi (Task Scheduling)

Presto sử dụng kiến trúc Master-Worker. Trong đó, một **Coordinator** (Máy chủ điều phối) phân tích kế hoạch truy vấn và tạo ra các **Stage** (Giai đoạn). Các Stage này được chia làm hai loại chính quyết định cách thức phân công tác vụ (Task) tới các **Worker**.

### Khái niệm chính

*   **Stage (Giai đoạn):** Một đơn vị công việc trong kế hoạch thực thi, tương ứng với một phần của cây kế hoạch truy vấn.
*   **Leaf Stage (Giai đoạn lá):** Là các Stage thực hiện việc đọc dữ liệu từ nguồn (Source). Đây là điểm bắt đầu của luồng dữ liệu.
*   **Intermediate Stage (Giai đoạn trung gian):** Là các Stage thực hiện các thao tác xử lý dữ liệu (như Join, Aggregation) trên dữ liệu được truyền từ các Stage khác.

### Chiến lược Lập kế hoạch (Scheduling Strategy)

| Loại Stage | Chiến lược Phân công (Scheduling) | Giải thích |
| :--- | :--- | :--- |
| **Leaf Stage** | **Ràng buộc nghiêm ngặt (Constraints)** | Trình lập kế hoạch phải cân nhắc:<br>1. **Vị trí dữ liệu (Data Locality):** Ưu tiên Worker nằm gần Storage Node (ví dụ: cùng Rack trong HDFS) để giảm băng thông mạng.<br>2. **Ràng buộc bộ kết nối (Connector Constraints):** Một số Connector (như Cassandra, MySQL) có thể yêu cầu Worker cụ thể phải xử lý dữ liệu của nó.<br>3. **Bố cục dữ liệu (Data Layout):** Đảm bảo Worker có thể truy cập dữ liệu hiệu quả. |
| **Intermediate Stage** | **Tự do (Any Worker)** | Các tác vụ tại Stage này chủ yếu xử lý dữ liệu đã được đọc sẵn hoặc dữ liệu trung gian. Do đó, chúng có thể được đặt trên bất kỳ Worker nào trong cụm (Cluster) để tận dụng tài nguyên tính toán tổng thể. |

### Ví dụ minh họa (Pseudo-code)

Hãy xem xét một truy vấn SQL cơ bản để hiểu cách Presto chia Stage:

```sql
-- Truy vấn: Lấy tổng doanh thu theo sản phẩm từ 2 bảng
SELECT p.name, SUM(o.amount)
FROM orders o
JOIN products p ON o.product_id = p.id
WHERE o.date > '2023-01-01'
GROUP BY p.name;
```

**Cách Presto chia Stage:**

1.  **Stage 1 (Leaf - Source Stage):** Đọc dữ liệu từ `orders` và `products`.
    *   *Scheduling:* Phân công Task đọc `orders` vào các Worker gần node lưu trữ file `orders` nhất.
2.  **Stage 2 (Intermediate - Exchange):** Phân tán dữ liệu (Exchange) để chuẩn bị cho Join (thường dựa trên `product_id`).
    *   *Scheduling:* Có thể đặt trên bất kỳ Worker nào.
3.  **Stage 3 (Intermediate - Join & Aggregation):** Thực hiện Join và tính toán `SUM`.
    *   *Scheduling:* Có thể đặt trên bất kỳ Worker nào.

---

## 2. Split Scheduling (Lập kế hoạch cho các phần dữ liệu)

Trong Presto, dữ liệu không được xử lý nguyên khối mà được chia nhỏ thành các **Split**. Đây là đơn vị dữ liệu nhỏ nhất mà một Task của Worker xử lý.

### Khái niệm chính

*   **Split (Phân mảnh):** Là một "handle" (bộ xử lý) không thể thay đổi (opaque handle) trỏ đến một khối dữ liệu có thể định địa chỉ.
    *   *Nguồn 1:* Dữ liệu外部 (External storage) như file trên HDFS/S3 (ví dụ: một file partition, một đoạn file - block).
    *   *Nguồn 2:* Kết quả trung gian (Intermediate results) được tạo ra bởi các Worker khác (thông qua Exchange).
*   **Lazy Assignment (Phân công chậm):** Split không được gán hết ngay từ đầu mà được tạo ra và gán dần trong quá trình truy vấn chạy.

### Quy trình Split Assignment

1.  **Enumerate (Liệt kê):** Khi query bắt đầu, Coordinator yêu cầu Connector liệt kê các Split tương ứng với file/partition được truy vấn.
2.  **Dispatch (Phân phối):** Split được gửi tới Worker.
3.  **Greedy Strategy (Chiến lược tham lam):** Split được gán cho Worker nào có **hàng đợi (Queue) ngắn nhất** tại thời điểm đó.

### Lợi ích của Lazy Assignment & Greedy Strategy

*   **Giảm tải Metadata:** Coordinator không cần nắm giữ toàn bộ danh sách Split của file dữ liệu lớn (có thể lên tới hàng triệu Split) trong bộ nhớ.
*   **Xử lý Streaming:** Truy vấn có thể bắt đầu trả kết quả mà không cần phải đọc/scan toàn bộ dữ liệu trước.
*   **Cân bằng tải (Load Balancing):** Gán Split cho Worker rảnh giúp tận dụng tài nguyên tốt hơn.

### Ví dụ thực tế: Đọc file trên HDFS

Giả sử bạn có một bảng `logs` lưu trữ dưới dạng text file trên HDFS với dung lượng 1TB.

*   **Split Size:** Presto mặc định chia mỗi Split khoảng 64MB hoặc 128MB (tùy cấu hình).
*   **Quy trình:**
    1.  Worker A đang xử lý Split 1 (đọc file `part-00000` từ offset 0 -> 64MB).
    2.  Worker A hoàn thành và báo cáo với Coordinator.
    3.  Coordinator thấy Worker B có hàng đợi rảnh, liền gửi Split 2 (đọc file `part-00000` từ offset 64MB -> 128MB) cho Worker B.

---

## 3. Query Optimization: Data Layouts (Tối ưu hóa Bố cục Dữ liệu)

Presto là một công cụ **MPP (Massively Parallel Processing)**. Để tối ưu hóa, Presto cần hiểu cách dữ liệu được sắp xếp trên đĩa (Physical Layout).

### Khái niệm chính

*   **Optimizer (Trình tối ưu):** Phân tích cấu trúc dữ liệu để tạo ra kế hoạch thực thi hiệu quả nhất.
*   **Physical Properties (Thuộc tính vật lý):**
    *   **Partitioning:** Dữ liệu được chia theo thư mục (ví dụ: `date=2023-01-01`).
    *   **Sorting:** Dữ liệu được sắp xếp bên trong file (ví dụ: theo `id`).
    *   **Grouping:** Dữ liệu được gom nhóm.
    *   **Indexes:** Chỉ mục (ít phổ biến trong Presto so với OLTP, nhưng quan trọng với các Connector như MySQL/Postgres).
*   **Multiple Layouts:** Một bảng có thể có nhiều cách bố trí. Ví dụ, dữ liệu thô (Raw) và dữ liệu đã được tối ưu cho truy vấn (Aggregated).

### Chiến lược tối ưu

Trình tối ưu chọn **bố cục tốt nhất** cho truy vấn cụ thể.
*   *Ví dụ:* Nếu truy vấn có `WHERE date = '2023-01-01'`, Presto sẽ ưu tiên đọc partition `date=2023-01-01` thay vì scan toàn bộ bảng (Partition Pruning).

### Ví dụ Code: Tạo bảng với Partitioning (Hive/Spark SQL)

Đây là cách người dùng tạo Data Layout để Presto tối ưu hóa:

```sql
-- Tạo bảng partitioned theo năm và tháng
CREATE TABLE sales_data (
    product_id INT,
    amount DOUBLE
)
PARTITIONED BY (year INT, month INT)
STORED AS PARQUET;

-- Khi insert dữ liệu, Hive/Spark sẽ tạo thư mục con
INSERT INTO sales_data PARTITION(year=2023, month=10) VALUES (101, 50000);

-- Khi Presto truy vấn: SELECT * FROM sales_data WHERE year=2023 AND month=10;
-- Kết quả: Presto chỉ quét thư mục /sales_data/year=2023/month=10, bỏ qua các phần còn lại.
```

---

## 4. Query Optimization: Predicate Pushdown (Đẩy mạnh điều kiện lọc)

Đây là kỹ thuật tối ưu quan trọng nhất để giảm lượng dữ liệu I/O.

### Khái niệm chính

*   **Predicate Pushdown:** Thay vì đọc hết dữ liệu lên Engine rồi mới lọc, Presto sẽ "đẩy" điều kiện lọc (Predicate) xuống càng gần nguồn dữ liệu càng tốt (thường là xuống Connector hoặc Storage).
*   **Two-part Constraint (Hai phần ràng buộc):** Presto cung cấp cho Connector thông tin để lọc:
    1.  **Domain of values:** Phạm vi giá trị (ví dụ: `id` nằm trong khoảng [100, 200]) và khả năng chứa NULL.
    2.  **"Black box" predicate:** Biểu thức logic chưa được giải mã đầy đủ (ví dụ: `id % 2 = 0`), để Connector tự quyết định cách xử lý nếu thông minh.

### Ví dụ thực tế

**Truy vấn:**
```sql
SELECT * FROM users WHERE age > 30 AND country = 'US';
```

**Kịch bản KHÔNG Predicate Pushdown (Kém hiệu quả):**
1.  Presto yêu cầu Connector đọc toàn bộ file `users.parquet`.
2.  Dữ liệu được chuyển qua mạng về Worker Presto.
3.  Worker Presto thực hiện lọc `age > 30` và `country = 'US'`.

**Kịch bản CÓ Predicate Pushdown (Hiệu quả):**
1.  Presto phân tích điều kiện và gửi yêu cầu tới Connector: "Hãy chỉ trả về dữ liệu thỏa mãn `age > 30` và `country = 'US'`".
2.  Connector (ví dụ: Connector cho S3/Parquet) đọc metadata của file Parquet.
3.  Connector phát hiện **Statistics** (Thống kê) của cột `country`: Min='US', Max='US'. Nó biết file này chỉ chứa dữ liệu 'US'.
4.  Connector chỉ đọc các Row Group chứa `age > 30`.
5.  Dữ liệu được lọc sẵn sàng trước khi gửi về Presto Engine.

---

## 5. Tổng kết & Ứng dụng trong thực tế

### Khi nào sử dụng Presto?
*   **Data Discovery & Ad-hoc Query:** Phân tích nhanh trên kho dữ liệu lớn (Data Lake) mà không cần chuyển dữ liệu.
*   **Unified Query Engine:** Truy vấn qua nhiều nguồn dữ liệu khác nhau (HDFS, S3, MySQL, Cassandra, Kafka) trong một câu lệnh SQL.
*   **Business Intelligence:** Kết nối với Tableau, PowerBI để báo cáo.

### Ưu & Nhược điểm

| Tiêu chí | Đánh giá |
| :--- | :--- |
| **Ưu điểm** | - **Phân tán thuần túy:** Khả năng mở rộng (Scalability) tốt.<br>- **Không cần ETL:** Truy vấn trực tiếp trên dữ liệu thô.<br>- **Thời gian phản hồi nhanh:** Phù hợp cho interactive queries.<br>- **Mô-đun hóa:** Architecture dựa trên Plugin/Connector linh hoạt. |
| **Nhược điểm** | - **Không lưu trữ:** Chỉ là engine query, phụ thuộc vào nguồn dữ liệu.<br>- **Độ trễ khởi động:** Đối với query nhỏ, overhead có thể cao hơn Hive.<br>- **Yêu cầu nguồn dữ liệu tốt:** Nếu dữ liệu không được tối ưu (không partition, file nhỏ lẻ), Presto chạy chậm. |

### Lời khuyên cho Kỹ sư Dữ liệu (Data Engineer)
Để tối đa hóa hiệu năng Presto, hãy luôn:
1.  **Cấu trúc dữ liệu tốt:** Luôn sử dụng **Partitioning** và định dạng file nhị phân (Parquet, ORC).
2.  **Cập nhật Statistics:** Đảm bảo Hive Metastore có thống kê cập nhật để Optimizer chọn plan tốt nhất.
3.  **Theo dõi Split Size:** Nếu task chạy quá nhanh (< 100ms) nhưng số lượng task quá lớn, hãy tăng `hive.max-split-size` để giảm overhead network.

---

Chào bạn, tôi là một chuyên gia về Big Data và Hệ thống Phân tán. Dưới đây là phân tích chi tiết về nội dung slide "4.6_presto.pdf" của bạn, được trình bày một cách chuyên nghiệp và chi tiết theo yêu cầu.

---

# Phân tích Hệ thống Query Engine: Presto

Tài liệu này cung cấp cái nhìn tổng quan về cách Presto xử lý các truy vấn, đặc biệt là cách nó tối ưu hóa việc thực thi song song và quản lý bộ nhớ.

## 1. Quy trình Query Execution (Thực thi truy vấn)

Presto nổi tiếng với khả năng thực thi truy vấn tốc độ cao trên các khối lượng dữ liệu lớn (Big Data) mà không cần lưu trữ dữ liệu đó. Quy trình này diễn ra cực kỳ hiệu quả thông qua các bước sau:

### Giải thích Khái niệm

*   **Logical Plan (Kế hoạch Logic):** Đây là bước đầu tiên trong quá trình dịch SQL. Presto phân tích câu lệnh SQL để hiểu ý định của người dùng (như lọc dữ liệu, nối bảng, tính toán tổng). Nó tạo ra một cây biểu thức (expression tree) trừu tượng mô tả các thao tác cần thực hiện.
*   **Distributed Plan (Kế hoạch Phân tán):** Sau khi có kế hoạch logic, Presto sẽ tối ưu hóa nó và biến đổi thành các tác vụ (tasks) có thể chạy song song trên nhiều node khác nhau trong cụm cluster.
*   **Stages, Tasks, and Splits:**
    *   **Stage:** Một truy vấn lớn được chia thành nhiều giai đoạn (stages). Mỗi stage hoàn thành sẽ truyền kết quả cho stage tiếp theo.
    *   **Task:** Các stage được chia nhỏ thành các task. Một task là đơn vị xử lý nhỏ nhất, chạy trên một worker node.
    *   **Split:** Dữ liệu đầu vào (ví dụ: một file trên S3) được chia thành các phần nhỏ gọi là splits. Các task sẽ lần lượt xử lý các splits này.
*   **Pipelined Execution (Thực thi ống dẫn):** Đây là điểm mạnh lớn nhất của Presto. Thay vì phải chờ một giai đoạn hoàn toàn trước khi giai đoạn sau bắt đầu, Presto truyền dữ liệu giữa các stage theo luồng liên tục. Ngay khi một task của stage 1 có dữ liệu, nó sẽ truyền ngay cho task của stage 2 xử lý.
*   **Memory-to-memory Data Transfer:** Presto ưu tiên chuyển dữ liệu trực tiếp giữa các node worker qua bộ nhớ (RAM). Nó tránh việc ghi dữ liệu đệm ra đĩa cứng (Disk IO), giúp tăng tốc độ xử lý đáng kể.

### Quy trình thực thi (Execution Flow)

1.  **SQL Parsing:** Trình phân tích cú pháp SQL của Presto nhận câu lệnh.
2.  **Logical Plan:** Tạo kế hoạch logic.
3.  **Distributed Plan:** Tạo kế hoạch phân tán, chia truy vấn thành các **Stages**.
4.  **Task & Split Scheduling:** Các Stage được chia thành **Tasks** và được phân bổ cho các Worker Nodes. Dữ liệu được chia thành **Splits** để các Task xử lý luân phiên.
5.  **Parallel Execution:** Tất cả các Task chạy song song.
6.  **Data Streaming:** Dữ liệu được truyền từ Task này sang Task khác (Pipelining) và giữa các Node (Memory-to-memory transfer).

### Quản lý Lỗi và Bộ nhớ

*   **Lỗi (Fail-fast):** Presto áp dụng cơ chế "thất bại nhanh". Nếu một Task nhỏ bị lỗi (ví dụ: lỗi đọc dữ liệu, lỗi tính toán), toàn bộ truy vấn sẽ bị hủy bỏ ngay lập tức. Điều này đảm bảo tính nhất致 của kết quả và tránh lãng phí tài nguyên cho một truy vấn đã sai.
*   **Bộ nhớ (Memory Management):** Presto giới hạn nghiêm ngặt bộ nhớ mà mỗi truy vấn có thể sử dụng.
    *   **Ưu điểm:** Nếu dữ liệu quá lớn (ví dụ: kết quả GROUP BY quá lớn), truy vấn sẽ fail thay vì làm sập server (Out of Memory). Worker node vẫn sống sót và sẵn sàng xử lý các truy vấn khác.
    *   **Nhược điểm:** Các truy vấn phức tạp với dữ liệu đầu vào khổng lồ có thể không thực thi được nếu không chia nhỏ hoặc tối ưu hóa.

---

## 2. Code Mẫu & Minh họa Kỹ thuật

Để hiểu rõ hơn, chúng ta hãy xem xét các ví dụ code minh họa cho các khái niệm trên.

### Ví dụ 1: Quy trình Logical Plan (SQL -> Operations)

Presto không công khai code cho phần "biên dịch" nội bộ, nhưng chúng ta có thể mô phỏng logic này bằng Python để hiểu cách một câu lệnh SQL được chuyển đổi thành các đối tượng xử lý.

```python
# Minh họa Logical Plan: Phân tích SQL thành các toán tử (Operators)

class Operator:
    def __init__(self, name):
        self.name = name
        self.children = []

    def add_child(self, child):
        self.children.append(child)

    def __repr__(self, level=0):
        ret = "  " * level + f"{self.name}\n"
        for child in self.children:
            ret += child.__repr__(level + 1)
        return ret

def create_logical_plan(sql_query):
    print(f"Processing SQL: {sql_query}")
    
    # Giả lập Presto Parser và Planner
    # SQL: SELECT region, SUM(sales) FROM orders WHERE year = 2023 GROUP BY region
    
    root = Operator("Output (Final Result)")
    
    # Stage 1: Aggregation (Group By)
    agg_op = Operator("Aggregate (GroupBy: region, SUM(sales))")
    root.add_child(agg_op)
    
    # Stage 2: Filtering (Where)
    filter_op = Operator("Filter (year = 2023)")
    agg_op.add_child(filter_op)
    
    # Stage 3: Table Scan (Read Data)
    scan_op = Operator("TableScan (orders)")
    filter_op.add_child(scan_op)
    
    return root

# Chạy thử
sql = "SELECT region, SUM(sales) FROM orders WHERE year = 2023 GROUP BY region"
logical_plan = create_logical_plan(sql)
print("\nLogical Plan Tree:")
print(logical_plan)
```

### Ví dụ 2: Cấu hình Presto (Presto Config)

Đây là ví dụ về file cấu hình `config.properties` để thiết lập môi trường Presto, liên quan đến việc quản lý bộ nhớ và worker nodes.

```properties
# config.properties - Cấu hình cho Coordinator Node
coordinator=true
node-scheduler.include-coordinator=false
http-server.http.port=8080
query.max-memory=50GB
query.max-memory-per-node=8GB
discovery.uri=http://localhost:8080

# Cấu hình cho Worker Node (thường giống nhau)
# coordinator=false
# http-server.http.port=8080
# query.max-memory=50GB
# query.max-memory-per-node=8GB
# discovery.uri=http://localhost:8080
```

*   **Giải thích:**
    *   `query.max-memory`: Tổng bộ nhớ tối đa cho tất cả các truy vấn đang chạy.
    *   `query.max-memory-per-node`: Bộ nhớ tối đa một truy vấn có thể chiếm trên một node đơn lẻ. Điều này ngăn chặn lỗi OOM (Out of Memory) và đảm bảo "query fails but worker doesn't die".

---

## 3. Hướng dẫn Sử dụng & Phân tích Ưu/Nhược điểm

### Khi nào sử dụng Presto? (Use Cases)

Presto được thiết kế cho các tình huống cần **truy vấn nhanh** trên dữ liệu lớn mà không cần di chuyển dữ liệu (Data Virtualization).

1.  **Data Lake Querying:** Truy vấn trực tiếp trên dữ liệu thô lưu trữ trong S3, HDFS, Azure Blob (dạng file Parquet, ORC, JSON, CSV).
2.  **OLAP (Online Analytical Processing):** Phân tích dữ liệu phức tạp, báo cáo (Reporting), khám phá dữ liệu (Data Discovery).
3.  **Federated Querying:** Nối dữ liệu từ nhiều nguồn khác nhau (ví dụ: MySQL + S3 + Kafka) trong một câu lệnh SQL duy nhất.

### Sử dụng như thế nào? (How to use)

1.  **Cài đặt:** Cài đặt Presto trên các node (1 Coordinator, nhiều Workers).
2.  **Kết nối Datasource:** Cấu hình các Connectors (MySQL, PostgreSQL, Hive, Kafka, v.v.) trong thư mục `etc/catalog/`.
3.  **Truy vấn:**
    *   **CLI:** Sử dụng công cụ `presto-cli` để chạy SQL trực tiếp.
    *   **JDBC/ODBC:** Tích hợp với các công cụ BI như Tableau, Superset, Looker hoặc các ứng dụng Java/Python.
    *   **Web UI:** Truy cập http://<coordinator>:8080 để giám sát các truy vấn đang chạy.

### Ưu & Nhược điểm

| Tiêu chí | Ưu điểm (Pros) | Nhược điểm (Cons) |
| :--- | :--- | :--- |
| **Tốc độ** | Rất nhanh do thực thi song song cao và Pipelining (không chờ đợi giữa các stage). | Không tối ưu cho các tác vụ ETL nặng (viết lại dữ liệu hàng loạt). |
| **Bộ nhớ** | Quản lý bộ nhớ tốt, không để lỗi OOM làm sập cả cluster. | Nếu truy vấn yêu cầu xử lý quá nhiều dữ liệu trong RAM, truy vấn sẽ fail. |
| **Dữ liệu** | Không cần di chuyển dữ liệu (Data Virtualization). Đọc trực tiếp trên storage. | Phụ thuộc nhiều vào định dạng file (Parquet/ORC cho hiệu suất cao nhất). |
| **Khả năng mở rộng** | Dễ dàng thêm Worker node để tăng công suất. | Coordinator có thể trở thành nút thắt cổ chai (bottleneck) nếu có quá nhiều truy vấn đồng thời. |

---

## 4. Ví dụ Thực tế trong Ngành Công nghiệp

### Case Study 1: Netflix (Phân tích Log & Dữ liệu Phim)
Netflix sử dụng Presto rộng rãi để phân tích log người dùng, hành vi xem phim và dữ liệu hệ thống.

*   **Bài toán:** "Needle-in-a-haystack" (Tìm kim trong đống cỏ). Tìm kiếm các sự kiện lỗi hiếm gặp trong hàng petabyte log được lưu trữ trên S3.
*   **Cách Presto giải quyết:**
    *   Dữ liệu được lưu trữ dưới dạng **Parquet** trên **S3**.
    *   Presto thực hiện **Table Scan** nhanh chóng, chỉ đọc các cột cần thiết (Projection Pushdown) và lọc dữ liệu (Predicate Pushdown).
    *   Với **Pipelined Execution**, kết quả được trả về gần như tức thời cho kỹ sư phân tích, giúp họ debug hệ thống nhanh hơn.

### Case Study 2: Qubole (Cloud Data Platform)
Qubole cung cấp dịch vụ Presto trên đám mây.

*   **Bài toán:** Khách hàng cần chạy các truy vấn SQL phức tạp (JOIN, GROUP BY) trên dữ liệu lưu trữ đám mây (AWS S3) với chi phí thấp và tốc độ cao.
*   **Cách Presto giải quyết:**
    *   **Auto-scaling:** Khi có truy vấn lớn, Qubole tự động thêm node worker (tăng quy mô).
    *   **Memory Management:** Áp dụng chính sách "query fails but worker doesn't die". Nếu một khách hàng chạy truy vấn "dại" (dùng quá nhiều RAM), truy vấn đó bị hủy, nhưng các khách hàng khác vẫn chạy bình thường nhờ các worker node vẫn hoạt động ổn định.

### Tóm tắt kỹ thuật từ Slide
*   **Bài toán Join + Group By:** Presto xử lý các truy vấn này bằng cách chia data thành các splits nhỏ, các worker thực hiện Join song song và truyền kết quả qua lại trong bộ nhớ (Memory-to-memory) để tính toán Group By cuối cùng.
*   **Bài toán Table Scan:** Đây là tác vụ đọc dữ liệu thô. Presto tối ưu hóa bằng cách đọc song song nhiều file (splits) trên nhiều worker node cùng lúc.

---

Chào bạn, với vai trò là một chuyên gia về Big Data và Hệ thống Phân tán, tôi sẽ phân tích và trình bày lại nội dung từ các slide về Presto một cách chi tiết, chuyên nghiệp và dễ hiểu theo đúng yêu cầu của bạn.

---

# Phân Tích & Tổng Hợp Kiến Thức Về Presto (Dựa trên Slide 4.6_presto.pdf)

Tài liệu slide này tập trung vào hiệu năng (performance) của PrestoDB, đặc biệt là khi so sánh với các công cụ khác và khi tối ưu hóa việc đọc dữ liệu định dạng ORC.

## 1. Khái Niệm & Giải Thích

### PrestoDB
- **Là gì?** Presto là một hệ thống truy vấn phân tán mã nguồn mở (distributed SQL query engine), được thiết kế để truy vấn dữ liệu quy mô lớn (petabyte-scale) trên nhiều nguồn dữ liệu khác nhau (data sources) như Hadoop (HDFS), S3, Cassandra, RDBMS...
- **Đặc điểm:** Nó không lưu trữ dữ liệu (storage-less), mà chỉ đóng vai trò là "bộ máy xử lý" truy vấn. Presto bỏ qua MapReduce framework của Hadoop để đạt tốc độ nhanh hơn đáng kể.

### ORC (Optimized Row Columnar)
- **Là gì?** Đây là một định dạng file lưu trữ dữ liệu có cấu trúc (columnar storage format) được tối ưu hóa cho Hadoop ecosystems (đặc biệt là Hive).
- **Tại sao quan trọng?** ORC giúp nén dữ liệu hiệu quả và hỗ trợ **predicate pushdown** (đẩy các điều kiện lọc dữ liệu xuống tận storage layer), giúp giảm lượng dữ liệu cần đọc và tăng tốc độ truy vấn.

### Benchmark (Đánh giá hiệu năng)
- **Là gì?** Quá trình chạy các bài тест tiêu chuẩn để so sánh hiệu suất giữa các hệ thống.
- **Nội dung slide đề cập:**
    - **Netflix Presto Benchmark:** Bài test hiệu năng do Netflix thực hiện.
    - **Cloudera Benchmark:** Bài test do Cloudera thực hiện, so sánh Hive và Presto.

---

## 2. Phân Tích Chi Tiết & Code Mẫu

### A. Tối Ưu Hóa Đọc Dữ Liệu ORC

Slide đề cập đến việc Presto đã cải thiện tốc độ đọc dữ liệu ORC như thế nào so với Hive.

#### Giải thích Khái niệm
- **Vấn đề:** Đọc dữ liệu từ file ORC cũ (qua Hive) thường chậm hơn so với Presto ORC Reader mới.
- **Giải pháp:** Presto đã phát triển một bộ đọc file ORC (ORC Reader) riêng biệt, tối ưu hóa cho việc đọc song song (parallel reading) và giảm overhead khi xử lý metadata.

#### Ví dụ thực tế (SQL)
Giả sử bạn có một bảng `sales` lưu dưới dạng ORC trong Hive. Khi bạn chạy truy vấn trên Presto, engine sẽ tối ưu hóa như sau:

```sql
-- Truy vấn lấy doanh thu theo khu vực
SELECT 
    region, 
    SUM(amount) as total_sales
FROM 
    hive_schema.sales_orc_table
WHERE 
    year = 2023 AND region = 'US'
GROUP BY 
    region;
```

**Presto ORC Reader hoạt động như thế nào?**
1.  **Column Pruning:** Chỉ đọc cột `region`, `amount`, `year` (bỏ qua các cột không dùng).
2.  **Predicate Pushdown:** Lọc dữ liệu `year = 2023` và `region = 'US'` trực tiếp khi đọc file, không tải hết dữ liệu năm 2023 về RAM rồi mới lọc.

#### Code Mẫu: Tối ưu hóa cấu trúc ORC (HiveQL)
Để tạo một bảng ORC tối ưu cho Presto, bạn nên dùng cấu trúc sau:

```sql
-- Tạo bảng với định dạng ORC và tối ưu hóa
CREATE TABLE sales_data_orc (
    id INT,
    order_date DATE,
    amount DOUBLE,
    region STRING
)
STORED AS ORC
TBLPROPERTIES (
    "orc.compress" = "ZLIB", -- Nén tốt
    "orc.stripe.size" = "67108864", -- Kích thước stripe tối ưu
    "orc.row.index.stride" = "10000" -- Tạo index cho mỗi 10k rows
);
```

### B. Bài Test Hiệu Năng (Benchmarks)

Slide đề cập đến các bài test từ Netflix và Cloudera để chứng minh tốc độ "Even faster".

#### Giải thích Khái niệm
- **Cloudera Benchmark (1 & 2):** Các bài test này thường so sánh Hive (cũ) và Presto trên cùng một khối lượng dữ liệu (ví dụ: 6 triệu rows từ TPC-H).
- **Kết quả chính:** Presto đọc các tập hợp cột khác nhau (various sets of columns) nhanh hơn đáng kể nhờ ORC Reader mới.

#### Ví dụ mô phỏng Benchmark (Python/Pandas)
Trong thực tế, các kỹ sư Data thường dùng script để tự động hóa benchmark. Dưới đây là pseudo-code minh họa logic của một bài test so sánh thời gian:

```python
import time
import presto
import hive_cursor

def benchmark_query(query, engine):
    start_time = time.time()
    
    if engine == 'presto':
        # Kết nối Presto
        conn = presto.connect(host='presto-server', port=8080)
        cursor = conn.cursor()
        cursor.execute(query)
        results = cursor.fetchall()
        
    elif engine == 'hive':
        # Kết nối Hive
        conn = hive_cursor.connect(host='hive-server', port=10000)
        cursor = conn.cursor()
        cursor.execute(query)
        results = cursor.fetchall()
        
    end_time = time.time()
    return end_time - start_time

# Dữ liệu test: 6 triệu rows
test_query = "SELECT count(*) FROM tpch.lineitem WHERE quantity > 10"

presto_time = benchmark_query(test_query, 'presto')
hive_time = benchmark_query(test_query, 'hive')

print(f"Presto: {presto_time}s, Hive: {hive_time}s")
print(f"Presto faster by: {hive_time/presto_time:.2f}x")
```

---

## 3. Hướng Dẫn Sử Dụng & Phân Tích Ưu/Nhược điểm

### Khi nào sử dụng Presto?

- **Use Cases:**
    - **Data Discovery & Ad-hoc Query:** Khi bạn cần chạy các truy vấn ngẫu nhiên, khám phá dữ liệu nhanh trên kho dữ liệu lớn (Data Lake).
    - **Truy vấn liên kết (Federated Query):** Cần join dữ liệu giữa Hive/S3 và MySQL/Postgres trong cùng một câu lệnh SQL.
    - **Business Intelligence (BI):** Nối với Tableau, Superset để báo cáo nhanh.

### Sử dụng Presto như thế nào?

1.  **Cài đặt:** Tải Presto từ trang chủ, cấu hình file `config.properties` và `catalog` (kết nối nguồn dữ liệu).
2.  **Truy vấn:**
    - **CLI:** Dùng command `presto-cli`.
    - **JDBC/ODBC:** Kết nối qua các công cụ BI.
    - **SQL:** Sử dụng cú pháp ANSI SQL chuẩn.

### Ưu & Nhược điểm

| Tiêu chí | Chi tiết |
| :--- | :--- |
| **Ưu điểm (Pros)** | • **Tốc độ:** Nhanh hơn Hive (thường từ 10-100x) vì không dùng MapReduce, xử lý in-memory.<br>• **Linh hoạt:** Hỗ trợ nhiều data sources (Hive, Kafka, RDBMS...).<br>• **Mở rộng:** Kiến trúc scale-out dễ dàng (thêm node worker là tăng tốc độ).<br>• **SQL Standard:** Hỗ trợ ANSI SQL, dễ tiếp cận. |
| **Nhược điểm (Cons)** | • **Không xử lý ETL:** Chỉ dùng để truy vấn (Read-only), không dùng để ghi/transform dữ liệu hàng loạt (ETL) như Spark.<br>• **Không lưu trữ:** Phụ thuộc hoàn toàn vào data source.<br>• **Memory Limit:** Nếu query quá phức tạp và bộ nhớ node Worker không đủ, query sẽ fail (Out of Memory). |

---

## 4. Ví dụ Thực Tế Trong Ngành

### Case Study: Netflix & Facebook (Tham chiếu từ slide)

1.  **Facebook (Tác giả của Presto):**
    - **Vấn đề:** Họ có hàng petabyte dữ liệu trong HDFS/Hive. Hive quá chậm cho việc phân tích ad-hoc của hàng nghìn nhân viên kỹ thuật và data scientist.
    - **Giải pháp:** Xây dựng Presto.
    - **Kết quả (Theo slide):** Sử dụng Presto ORC Reader mới, họ đạt được tốc độ "Data at the speed of Presto", xử lý 6 triệu rows trong TPC-H chỉ trong tích tắc, nhanh hơn rất nhiều so với Hive-based ORC reader.

2.  **Netflix:**
    - **Vấn đề:** Phân tích dữ liệu người dùng và log streaming theo thời gian thực để tối ưu hóa trải nghiệm video.
    - **Áp dụng:** Sử dụng Presto để cho phép các kỹ sư dữ liệu chạy truy vấn nhanh trên dữ liệu lưu trữ trên Amazon S3 (Data Lake).

### Case Study: Hệ thống Phân tích Log (Minh họa)

Giả sử bạn là một công ty E-commerce, bạn có hàng triệu log truy cập website mỗi ngày lưu trong file `.log` trên S3, chuyển đổi sang định dạng **Parquet/ORC**.

- **Bước 1:** Dùng **Presto** để kết nối catalog S3.
- **Bước 2:** Chạy SQL để tìm top 10 trang được xem nhiều nhất trong ngày:

```sql
SELECT 
    page_url, 
    COUNT(*) as view_count
FROM 
    s3_logs.access_logs
WHERE 
    date = CURRENT_DATE - INTERVAL '1' DAY
GROUP BY 
    page_url
ORDER BY 
    view_count DESC
LIMIT 10;
```

- **Lợi ích:** Kết quả trả về trong vài giây, giúp team Product nhanh chóng điều chỉnh giao diện website mà không cần chờ batch job chạy qua đêm.

---

## 5. Tài liệu Tham Kham chiếu (References)

Dựa trên slide, đây là các nguồn tài liệu gốc uy tín để bạn tìm hiểu sâu hơn:

1.  **Facebook Engineering Blog:** [Even faster: Data at the speed of Presto ORC](https://code.facebook.com/posts/370832626374903/even-faster-data-at-the-speed-of-presto-orc/)
2.  **Facebook Engineering Blog:** [Presto: Interacting with petabytes of data at Facebook](https://www.facebook.com/notes/facebook-engineering/presto-interacting-with-petabytes-of-data-at-facebook/10151786197628920/)
3.  **Bài báo khoa học:** Traverso, Martin. "Presto: Interacting with petabytes of data at Facebook." (2014).
4.  **SlideShare:** [Presto Hadoop Conference Japan 2014](https://www.slideshare.net/frsyuki/presto-hadoop-conference-japan-2014) (Tác giả: Syuhei Fukuda).

---

